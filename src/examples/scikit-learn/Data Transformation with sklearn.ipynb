{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Transformation with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading some data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X=load_iris()['data'] #vectors of data\n",
    "y=load_iris()['target'] #label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 lines of X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "\n",
      "Labels\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 lines of X:\\n\", X[0:10])\n",
    "print(\"\\nLabels\\n\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split into train and test data (corresponds to \"Partitioning\" node in KNIME)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some general notes on data transformation in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All transformers have implemented the method ``fit``. This method is used to learn model parameters from a training set. (**Make sure you don't fit your transformation data on the test dataset!**)\n",
    "* Furthermore, all transformers have  a method ``transform``. This method applies the transformation model to unseen data.\n",
    "* In addition, the method ``fit_transform`` exists, which can be called for modelling and transforming the training data simultaneously. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***sklearn*** provides a wide range of pre-processing methods on ***NumPy*** arrays and other input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4134164 , -1.46200287, -0.09951105, -0.32339776],\n",
       "       [ 0.55122187, -0.50256349,  0.71770262,  0.35303182],\n",
       "       [ 0.67180165,  0.21701605,  0.95119225,  0.75888956],\n",
       "       [ 0.91296121, -0.02284379,  0.30909579,  0.2177459 ],\n",
       "       [ 1.63643991,  1.41631528,  1.30142668,  1.70589097],\n",
       "       [-0.17225683, -0.26270364,  0.19235097,  0.08245999],\n",
       "       [ 2.11875905, -0.02284379,  1.59328871,  1.16474731],\n",
       "       [-0.29283662, -0.02284379,  0.36746819,  0.35303182],\n",
       "       [-0.89573553,  1.17645543, -1.44207638, -1.40568508],\n",
       "       [ 2.23933883, -0.50256349,  1.65166111,  1.0294614 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example scaling data\n",
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "\n",
    "X_scaled [0:10,:]                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scaling\n",
    "One problem with scaling - as with all other pre-processing methods - is, that we need to find the \"right\" processing steps based on the **train data** and the also apply it to the **test data**. **Sklearn*** provides ***Scaler*** models to do this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Instantiate the class\n",
    "Check out the API documentation for parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Fit to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  [5.84285714 3.00952381 3.87047619 1.23904762]\n",
      "Standard dev. =  [0.82932642 0.41691013 1.71313824 0.73917525]\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(X_train)\n",
    "\n",
    "# Now the mean and the standard deviation have been determined for all features and \n",
    "# are stored in the scaler instance. We can retrieve them if we want. \n",
    "print(\"Mean = \", scaler.mean_)\n",
    "print(\"Standard dev. = \", scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Apply transformation to data                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4134164  -1.46200287 -0.09951105 -0.32339776]\n",
      " [ 0.55122187 -0.50256349  0.71770262  0.35303182]\n",
      " [ 0.67180165  0.21701605  0.95119225  0.75888956]\n",
      " [ 0.91296121 -0.02284379  0.30909579  0.2177459 ]\n",
      " [ 1.63643991  1.41631528  1.30142668  1.70589097]\n",
      " [-0.17225683 -0.26270364  0.19235097  0.08245999]\n",
      " [ 2.11875905 -0.02284379  1.59328871  1.16474731]\n",
      " [-0.29283662 -0.02284379  0.36746819  0.35303182]\n",
      " [-0.89573553  1.17645543 -1.44207638 -1.40568508]\n",
      " [ 2.23933883 -0.50256349  1.65166111  1.0294614 ]\n",
      " [-0.05167705 -0.74242333  0.13397857 -0.32339776]\n",
      " [-0.77515575  0.93659559 -1.44207638 -1.40568508]\n",
      " [-1.01631531  1.17645543 -1.50044878 -1.27039917]\n",
      " [-0.89573553  1.89603497 -1.15021435 -1.13511325]\n",
      " [-1.01631531 -2.42144225 -0.21625586 -0.32339776]\n",
      " [ 0.55122187 -0.74242333  0.60095781  0.75888956]\n",
      " [-1.25747488  0.93659559 -1.15021435 -1.40568508]\n",
      " [-1.01631531 -0.02284379 -1.32533157 -1.40568508]\n",
      " [-0.89573553  0.69673574 -1.26695916 -0.99982734]\n",
      " [-0.29283662 -0.74242333  0.19235097  0.08245999]\n",
      " [-0.89573553  0.93659559 -1.38370397 -1.40568508]\n",
      " [-0.17225683 -0.02284379  0.19235097 -0.05282593]\n",
      " [ 2.23933883  1.89603497  1.65166111  1.30003323]\n",
      " [-1.49863445  0.4568759  -1.44207638 -1.40568508]\n",
      " [ 0.43064208 -0.26270364  0.25072338  0.08245999]\n",
      " [-0.17225683 -1.22214302  0.65933022  1.0294614 ]\n",
      " [-0.4134164   2.85547435 -1.44207638 -1.40568508]\n",
      " [ 0.18948252 -0.02284379  0.54258541  0.75888956]\n",
      " [-0.05167705 -0.74242333  0.71770262  0.89417548]\n",
      " [ 0.18948252 -1.94172256  0.07560616 -0.32339776]\n",
      " [-0.53399618 -0.02284379  0.36746819  0.35303182]\n",
      " [ 0.43064208  0.93659559  0.89281984  1.43531914]\n",
      " [-0.4134164  -1.70186271  0.07560616  0.08245999]\n",
      " [-0.53399618  2.13589481 -1.26695916 -1.13511325]\n",
      " [-1.01631531 -1.70186271 -0.33300068 -0.32339776]\n",
      " [ 0.67180165 -0.74242333  0.83444743  0.89417548]\n",
      " [-1.01631531  0.69673574 -1.44207638 -1.40568508]\n",
      " [-1.01631531  0.4568759  -1.55882119 -1.40568508]\n",
      " [-0.4134164  -1.46200287 -0.04113865 -0.18811184]\n",
      " [ 1.033541   -0.02284379  0.65933022  0.62360365]\n",
      " [-1.1368951   0.21701605 -1.38370397 -1.40568508]\n",
      " [-0.05167705 -0.50256349  0.71770262  1.57060506]\n",
      " [-1.01631531  0.93659559 -1.38370397 -1.40568508]\n",
      " [-1.01631531  1.17645543 -1.32533157 -0.86454142]\n",
      " [ 0.06890273  0.4568759   0.54258541  0.75888956]\n",
      " [-0.89573553 -1.22214302 -0.50811789 -0.18811184]\n",
      " [ 1.27470056  0.4568759   1.06793706  1.43531914]\n",
      " [ 0.18948252 -0.74242333  0.71770262  0.48831773]\n",
      " [ 0.3100623  -0.98228318  1.00956465  0.2177459 ]\n",
      " [ 2.23933883 -0.02284379  1.30142668  1.43531914]\n",
      " [-0.4134164  -1.22214302  0.07560616  0.08245999]\n",
      " [-1.73979401 -0.26270364 -1.44207638 -1.40568508]\n",
      " [-1.8603738  -0.02284379 -1.6171936  -1.540971  ]\n",
      " [ 0.18948252 -1.94172256  0.65933022  0.35303182]\n",
      " [ 1.63643991  0.4568759   1.24305427  0.75888956]\n",
      " [-1.49863445  0.21701605 -1.38370397 -1.40568508]\n",
      " [-0.89573553  1.17645543 -1.44207638 -1.27039917]\n",
      " [-1.73979401 -0.02284379 -1.50044878 -1.40568508]\n",
      " [ 0.55122187 -1.22214302  0.60095781  0.35303182]\n",
      " [ 0.55122187  0.93659559  1.00956465  1.57060506]\n",
      " [-1.49863445  0.93659559 -1.44207638 -1.27039917]\n",
      " [ 1.15412078 -0.02284379  0.95119225  1.16474731]\n",
      " [ 0.55122187  0.69673574  1.24305427  1.70589097]\n",
      " [-1.37805466  0.4568759  -1.50044878 -1.40568508]\n",
      " [ 0.3100623  -0.26270364  0.484213    0.2177459 ]\n",
      " [ 0.79238143 -0.50256349  0.4258406   0.35303182]\n",
      " [ 0.43064208 -0.50256349  0.54258541  0.75888956]\n",
      " [ 1.39528035  0.4568759   0.484213    0.2177459 ]\n",
      " [ 0.67180165  0.4568759   0.83444743  1.43531914]\n",
      " [-0.89573553  1.89603497 -1.32533157 -1.40568508]\n",
      " [ 1.27470056  0.21701605  0.89281984  1.16474731]\n",
      " [ 0.06890273 -0.02284379  0.19235097  0.35303182]\n",
      " [ 0.79238143 -0.02284379  0.77607503  1.0294614 ]\n",
      " [-0.17225683 -0.98228318 -0.21625586 -0.32339776]\n",
      " [-0.77515575 -0.74242333  0.01723376  0.2177459 ]\n",
      " [ 0.3100623  -0.02284379  0.4258406   0.2177459 ]\n",
      " [-1.61921423 -1.70186271 -1.50044878 -1.27039917]\n",
      " [ 0.91296121 -0.26270364  0.4258406   0.08245999]\n",
      " [-0.4134164  -0.98228318  0.30909579 -0.05282593]\n",
      " [-0.65457597  1.65617512 -1.38370397 -1.40568508]\n",
      " [-0.29283662 -0.02284379  0.13397857  0.08245999]\n",
      " [ 1.7570197  -0.26270364  1.41817149  0.75888956]\n",
      " [ 1.033541    0.69673574  1.06793706  1.16474731]\n",
      " [-0.89573553  1.65617512 -1.38370397 -1.13511325]\n",
      " [-1.1368951  -1.46200287 -0.33300068 -0.32339776]\n",
      " [ 1.033541    0.69673574  1.06793706  1.70589097]\n",
      " [ 1.63643991 -0.02284379  1.12630946  0.48831773]\n",
      " [-1.1368951   1.41631528 -1.44207638 -1.540971  ]\n",
      " [ 1.033541    0.21701605  1.00956465  1.57060506]\n",
      " [-1.1368951  -0.02284379 -1.44207638 -1.40568508]\n",
      " [ 1.27470056  0.21701605  0.60095781  0.35303182]\n",
      " [ 1.87759948 -0.50256349  1.30142668  0.89417548]\n",
      " [ 0.55122187 -0.26270364  1.00956465  0.75888956]\n",
      " [-0.17225683 -0.50256349  0.13397857  0.08245999]\n",
      " [ 0.79238143 -0.02284379  0.95119225  0.75888956]\n",
      " [ 0.55122187 -1.70186271  0.30909579  0.08245999]\n",
      " [ 0.67180165 -0.26270364  0.25072338  0.08245999]\n",
      " [-0.29283662 -0.50256349  0.60095781  1.0294614 ]\n",
      " [ 0.06890273 -0.02284379  0.71770262  0.75888956]\n",
      " [-0.53399618  0.93659559 -1.26695916 -1.40568508]\n",
      " [ 0.3100623  -0.50256349  0.07560616  0.08245999]\n",
      " [-1.1368951  -1.22214302  0.36746819  0.62360365]\n",
      " [-0.05167705  2.37575466 -1.55882119 -1.40568508]\n",
      " [-0.05167705 -0.98228318  0.07560616 -0.05282593]\n",
      " [ 1.51586013 -0.02284379  1.18468187  1.16474731]]\n"
     ]
    }
   ],
   "source": [
    "transformed = scaler.transform(X_train)                           \n",
    "\n",
    "# The data the transformation is applied to does not have to be the same than the data that\n",
    "# the model has been fitted with. But if the same data that is used for fitting has to be \n",
    "# transformed, we also could use method *.fit_transform() to perform both steps at once. \n",
    "\n",
    "# transformed = scaler.fit_transform(X_train)  #in this case the fit method wouldn't have to be called separately\n",
    "\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scaler\n",
    "There are many different ***Scaler*** available. See [Examples here](https://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Encoding categorical features as numbers\n",
    "\n",
    "**sklearn** cannot deal with categorical data. Therefore, categories have to be encoded as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class2\n",
       "1    red    L   13.5     class1\n",
       "2   blue   XL   15.3     class2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "import pandas as pd\n",
    "\n",
    "def initializeData(): \n",
    "    df = pd.DataFrame([\n",
    "                ['green', 'M', 10.1, 'class2'],\n",
    "                ['red', 'L', 13.5, 'class1'],\n",
    "                ['blue', 'XL', 15.3, 'class2']])\n",
    "    df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "    return df\n",
    "\n",
    "df = initializeData()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a list of all columns with categorical variables with dtype ``object`` by checking the data type of each column. (Note that this way you don't get categorical variables which are already converted into numerical values or which are assigned a different data type!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['color', 'size', 'classlabel']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (df.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mapping categorical target variables to numbers**\n",
    "\n",
    "The LabelEncoder can be used to transform non-numerical labels to numerical labels.  \n",
    "The labels in the columns are alphabetically sorted to define the mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers correspond to alphabetic order of labels:  ['class1' 'class2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price  classlabel\n",
       "0  green    M   10.1           1\n",
       "1    red    L   13.5           0\n",
       "2   blue   XL   15.3           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['classlabel'] = label_encoder.fit_transform(df['classlabel'])\n",
    "\n",
    "print(\"Numbers correspond to alphabetic order of labels: \", label_encoder.classes_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mapping categorical features to numbers**\n",
    "\n",
    "The OrdinalEncoder is used to transform numerical features to numbers.  \n",
    "Again, the numbers are assigned in the alphabetic order of the categories of the feature.  \n",
    "Note that in contrast to the LabelEncoder the OrdinalEncoder expects a two-dimensional input (which means that it also accepts multiple features at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['blue', 'green', 'red'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price  classlabel\n",
       "0    1.0    M   10.1           1\n",
       "1    2.0    L   13.5           0\n",
       "2    0.0   XL   15.3           1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "df['color'] = ordinal_encoder.fit_transform(df[['color']])\n",
    "\n",
    "\n",
    "print(ordinal_encoder.categories_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mapping ordinal feature to numbers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Define the mapping\n",
    "It cannot be \"guessed\" by an algorithm what a meaningful order looks like, so have to provide this information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_mapping = {'XL': 3, \n",
    "               'L':2, \n",
    "               'M':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Apply the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price  classlabel\n",
       "0    1.0     1   10.1           1\n",
       "1    2.0     2   13.5           0\n",
       "2    0.0     3   15.3           1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['size'] = df['size'].map(size_mapping)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     M\n",
       "1     L\n",
       "2    XL\n",
       "Name: size, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If needed, a reverse mapping can be implemented as well\n",
    "inv_size_mapping = {v: k for k, v in size_mapping.items()}\n",
    "df = df['size'].map(inv_size_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### **One-Hot Encoding**\n",
    "One issue with the transformation of the OrdinalEncoder is that ML algorithms will assume that two nearby values are more similar than two distant values. However, this is not always the case.   \n",
    "Another possibility to convert categorical features to features is to use a ***one-hot*** or dummy encoding. This transforms each categorical feature with **$n$ categories** possible values into **$n$ categories binary features**, with one of them 1, and all others 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-0fa2cbecdcad>:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  transformed = one_hot_encoder.fit_transform(df2['color'][:,np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df2 = initializeData()\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "transformed = one_hot_encoder.fit_transform(df2['color'][:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the output is a SciPy sparse matrix, not a NumPy array! \n",
    "type(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformed to a dense NumPy array it looks like this\n",
    "transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel    0    1    2\n",
       "0  green    M   10.1     class2  0.0  1.0  0.0\n",
       "1    red    L   13.5     class1  0.0  0.0  1.0\n",
       "2   blue   XL   15.3     class2  1.0  0.0  0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the new columns to the data frame\n",
    "#df2 = pd.concat([df2,pd.DataFrame(transformed.toarray())], axis = 1)\n",
    "df2 = df2.join(pd.DataFrame(transformed.toarray()))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  size  price classlabel    0    1    2\n",
       "0    M   10.1     class2  0.0  1.0  0.0\n",
       "1    L   13.5     class1  0.0  0.0  1.0\n",
       "2   XL   15.3     class2  1.0  0.0  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the original column\n",
    "df2 = df2.drop(\"color\", axis = 1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to get a one-hot encoding is to use the method ``get_dummies()`` of pandas. One advantage of this approach is that you can specify a prefix for the new columns.   \n",
    "More information: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  size  price classlabel  color_blue  color_green  color_red\n",
       "0    M   10.1     class2           0            1          0\n",
       "1    L   13.5     class1           0            0          1\n",
       "2   XL   15.3     class2           1            0          0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = initializeData()\n",
    "df3 = pd.get_dummies(df3, columns = [\"color\"], prefix=\"color\" )\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Discretization\n",
    "\n",
    "Binning continuous data into intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 1., 3., 2.],\n",
       "       [2., 4., 1., 1.],\n",
       "       [4., 0., 4., 4.],\n",
       "       [2., 2., 2., 3.],\n",
       "       [4., 1., 3., 2.],\n",
       "       [1., 4., 1., 1.],\n",
       "       [2., 2., 1., 2.],\n",
       "       [4., 3., 3., 4.],\n",
       "       [3., 0., 2., 3.],\n",
       "       [2., 1., 1., 2.],\n",
       "       [3., 3., 3., 4.],\n",
       "       [0., 3., 0., 0.],\n",
       "       [1., 4., 0., 1.],\n",
       "       [0., 3., 1., 0.],\n",
       "       [1., 4., 1., 1.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [3., 3., 4., 4.],\n",
       "       [2., 0., 1., 1.],\n",
       "       [2., 1., 2., 2.],\n",
       "       [3., 1., 4., 4.],\n",
       "       [0., 3., 1., 1.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [1., 4., 1., 1.],\n",
       "       [3., 1., 4., 4.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [4., 3., 3., 4.],\n",
       "       [4., 0., 4., 3.],\n",
       "       [4., 3., 4., 4.],\n",
       "       [0., 3., 0., 1.],\n",
       "       [0., 3., 1., 1.],\n",
       "       [0., 4., 0., 1.],\n",
       "       [2., 4., 1., 1.],\n",
       "       [4., 3., 2., 2.],\n",
       "       [0., 4., 1., 1.],\n",
       "       [0., 3., 0., 1.],\n",
       "       [3., 0., 3., 4.],\n",
       "       [3., 3., 2., 3.],\n",
       "       [1., 4., 1., 1.],\n",
       "       [1., 4., 0., 1.],\n",
       "       [1., 4., 1., 0.],\n",
       "       [2., 1., 3., 4.],\n",
       "       [2., 4., 2., 3.],\n",
       "       [4., 3., 3., 3.],\n",
       "       [1., 4., 0., 1.],\n",
       "       [1., 4., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#discretize data by dimension\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "disc = KBinsDiscretizer(n_bins = 5, encode='ordinal').fit(X_train)\n",
    "disc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many datasets contain features of different types, say text, floats, and dates, where each type of feature requires separate preprocessing or feature extraction steps. The ColumnTransformer helps performing different transformations for different columns. It can also be included in a Pipeline. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color          object\n",
      "size           object\n",
      "price         float64\n",
      "classlabel     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.32954369,  1.        ,  1.        ,  1.        ],\n",
       "       [ 0.24735697,  2.        ,  0.        ,  0.        ],\n",
       "       [ 1.08218672,  0.        ,  2.        ,  1.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "df4 = initializeData()\n",
    "num_attributes = ['price']\n",
    "cat_attributes = ['color', 'size', 'classlabel']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", scaler, num_attributes), \n",
    "    (\"cat\", OrdinalEncoder(), cat_attributes)\n",
    "])\n",
    "\n",
    "prepared = full_pipeline.fit_transform(df4)\n",
    "prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines\n",
    "***Pipeline*** can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
    "\n",
    "* Convenience and encapsulation\n",
    "    \n",
    "* The parameters of the transformers can be included in the parameter selection\n",
    "   \n",
    "* Avoiding data leakage: Ensures that statistics from the validation data is not incorporated into the preprocessors which would make cross-validation scores unreliable. \n",
    "   \n",
    "\n",
    "All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).\n",
    "\n",
    "Docs: https://scikit-learn.org/stable/modules/compose.html#pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating, filling and using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating and filling a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('nearest neighbor', knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to give names to the steps of the pipeline, you can use make_pipeline instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(scaler, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "livereveal": {
   "enable_chalkboard": true,
   "footer": "Janis Keuper - SS19",
   "header": "Data Science: Block 5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
