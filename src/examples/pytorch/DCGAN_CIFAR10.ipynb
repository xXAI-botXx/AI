{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a0fff480685404f83667601f47966a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_370c1f37cb754aed8b21db2b596880dc",
              "IPY_MODEL_5c5ff266bbdc4609b2403a129d7b6672",
              "IPY_MODEL_6fa094cdeb9440a1957ae253bfa9b3a5"
            ],
            "layout": "IPY_MODEL_3dee638d91274e1b9a2c5a84da75bd4e"
          }
        },
        "370c1f37cb754aed8b21db2b596880dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf857275ac9401a8fd6fec8ff3b9688",
            "placeholder": "​",
            "style": "IPY_MODEL_ade85125e92e41808d46e32998b36d36",
            "value": ""
          }
        },
        "5c5ff266bbdc4609b2403a129d7b6672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b673813033b74bdc85fec385b2a902cc",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83e98d4278294da0a38ece8fed10da34",
            "value": 170498071
          }
        },
        "6fa094cdeb9440a1957ae253bfa9b3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e07cc82af44ec2a223b4f108a662f0",
            "placeholder": "​",
            "style": "IPY_MODEL_368b73675fa6493bac1da79aeb1b1f92",
            "value": " 170499072/? [00:13&lt;00:00, 15827591.97it/s]"
          }
        },
        "3dee638d91274e1b9a2c5a84da75bd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf857275ac9401a8fd6fec8ff3b9688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade85125e92e41808d46e32998b36d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b673813033b74bdc85fec385b2a902cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e98d4278294da0a38ece8fed10da34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2e07cc82af44ec2a223b4f108a662f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368b73675fa6493bac1da79aeb1b1f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i0AIosM0AaY2"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set manual seed to a constant get a consistent output\n",
        "manualSeed = random.randint(1, 10000)\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRd7ls4aAm04",
        "outputId": "60c81cbe-8830-4cd0-b4b5-4223e269b26a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  3062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd129a0a690>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "dataset = dset.CIFAR10(root=\"./data\", download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(64),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "nc=3\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
        "                                         shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "6a0fff480685404f83667601f47966a0",
            "370c1f37cb754aed8b21db2b596880dc",
            "5c5ff266bbdc4609b2403a129d7b6672",
            "6fa094cdeb9440a1957ae253bfa9b3a5",
            "3dee638d91274e1b9a2c5a84da75bd4e",
            "1bf857275ac9401a8fd6fec8ff3b9688",
            "ade85125e92e41808d46e32998b36d36",
            "b673813033b74bdc85fec385b2a902cc",
            "83e98d4278294da0a38ece8fed10da34",
            "b2e07cc82af44ec2a223b4f108a662f0",
            "368b73675fa6493bac1da79aeb1b1f92"
          ]
        },
        "id": "is2FpH_lAtJJ",
        "outputId": "93b423e2-d2cd-4c8c-bfe8-b797793efd52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a0fff480685404f83667601f47966a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the availability of cuda devices\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "yF-tedlhAx-s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of gpu's available\n",
        "ngpu = 1\n",
        "# input noise dimension\n",
        "nz = 100\n",
        "# number of generator filters\n",
        "ngf = 64\n",
        "#number of discriminator filters\n",
        "ndf = 64"
      ],
      "metadata": {
        "id": "udvN8fkkA4Ob"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "uLRkJtYVA8dM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "            return output"
      ],
      "metadata": {
        "id": "mEBGAGrNBAWc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init Generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "#load weights to test the model\n",
        "#netG.load_state_dict(torch.load('weights/netG_epoch_24.pth'))\n",
        "print(netG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386mHXzFBFJE",
        "outputId": "c9195a8b-0fa3-414a-9ad1-7b06f92f4f00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)"
      ],
      "metadata": {
        "id": "ROWHi8XKBJGl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)\n",
        "#load weights to test the model \n",
        "#netD.load_state_dict(torch.load('weights/netD_epoch_24.pth'))\n",
        "print(netD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chnQl_lgBPXl",
        "outputId": "daba88c8-057c-4f1c-8968-df798c6df13e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setup training\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# setup optimizer\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "fixed_noise = torch.randn(128, nz, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "niter = 25\n",
        "g_loss = []\n",
        "d_loss = []"
      ],
      "metadata": {
        "id": "q9GGxsVXBTZV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train!\n",
        "for epoch in range(niter):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device, dtype=torch.float)\n",
        "\n",
        "        output = netD(real_cpu)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        \n",
        "        #save the output\n",
        "        if i % 100 == 0:\n",
        "            print('saving the output')\n",
        "            vutils.save_image(real_cpu,'real_samples.png',normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(),'fake_samples_epoch_%03d.png' % (epoch),normalize=True)\n",
        "    \n",
        "    # Check pointing for every epoch\n",
        "    torch.save(netG.state_dict(), 'netG_epoch_%d.pth' % (epoch))\n",
        "    torch.save(netD.state_dict(), 'netD_epoch_%d.pth' % (epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4046tXiBZgG",
        "outputId": "1d3c1907-ca79-4b4d-d459-855daba3ac16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/25][0/391] Loss_D: 1.3972 Loss_G: 7.3705 D(x): 0.9413 D(G(z)): 0.5978 / 0.0016\n",
            "saving the output\n",
            "[0/25][1/391] Loss_D: 0.8361 Loss_G: 3.7541 D(x): 0.5357 D(G(z)): 0.0212 / 0.0863\n",
            "[0/25][2/391] Loss_D: 0.8778 Loss_G: 3.4946 D(x): 0.7826 D(G(z)): 0.3366 / 0.0624\n",
            "[0/25][3/391] Loss_D: 0.9026 Loss_G: 6.1541 D(x): 0.8324 D(G(z)): 0.4182 / 0.0047\n",
            "[0/25][4/391] Loss_D: 0.7884 Loss_G: 2.9884 D(x): 0.5852 D(G(z)): 0.0713 / 0.0825\n",
            "[0/25][5/391] Loss_D: 0.9776 Loss_G: 6.3779 D(x): 0.8577 D(G(z)): 0.4767 / 0.0042\n",
            "[0/25][6/391] Loss_D: 1.3565 Loss_G: 1.6324 D(x): 0.3870 D(G(z)): 0.0521 / 0.3323\n",
            "[0/25][7/391] Loss_D: 1.6495 Loss_G: 8.1778 D(x): 0.9706 D(G(z)): 0.7106 / 0.0007\n",
            "[0/25][8/391] Loss_D: 1.4140 Loss_G: 4.4157 D(x): 0.3648 D(G(z)): 0.0067 / 0.0321\n",
            "[0/25][9/391] Loss_D: 0.3442 Loss_G: 4.1635 D(x): 0.9530 D(G(z)): 0.2041 / 0.0362\n",
            "[0/25][10/391] Loss_D: 0.4690 Loss_G: 5.8614 D(x): 0.9528 D(G(z)): 0.2885 / 0.0051\n",
            "[0/25][11/391] Loss_D: 0.3901 Loss_G: 3.9213 D(x): 0.7564 D(G(z)): 0.0467 / 0.0337\n",
            "[0/25][12/391] Loss_D: 0.3498 Loss_G: 4.1084 D(x): 0.9059 D(G(z)): 0.1997 / 0.0242\n",
            "[0/25][13/391] Loss_D: 0.4296 Loss_G: 4.0045 D(x): 0.8173 D(G(z)): 0.1663 / 0.0285\n",
            "[0/25][14/391] Loss_D: 0.5644 Loss_G: 5.6160 D(x): 0.8446 D(G(z)): 0.2685 / 0.0065\n",
            "[0/25][15/391] Loss_D: 0.4318 Loss_G: 3.6543 D(x): 0.7386 D(G(z)): 0.0624 / 0.0447\n",
            "[0/25][16/391] Loss_D: 0.4345 Loss_G: 5.4293 D(x): 0.8914 D(G(z)): 0.2489 / 0.0073\n",
            "[0/25][17/391] Loss_D: 0.4615 Loss_G: 3.1972 D(x): 0.7113 D(G(z)): 0.0542 / 0.0622\n",
            "[0/25][18/391] Loss_D: 0.4032 Loss_G: 5.7208 D(x): 0.9244 D(G(z)): 0.2509 / 0.0053\n",
            "[0/25][19/391] Loss_D: 0.2316 Loss_G: 4.6536 D(x): 0.8630 D(G(z)): 0.0504 / 0.0138\n",
            "[0/25][20/391] Loss_D: 0.2150 Loss_G: 3.9832 D(x): 0.9029 D(G(z)): 0.0934 / 0.0267\n",
            "[0/25][21/391] Loss_D: 0.3497 Loss_G: 4.1931 D(x): 0.8875 D(G(z)): 0.1777 / 0.0226\n",
            "[0/25][22/391] Loss_D: 0.2691 Loss_G: 3.9627 D(x): 0.8857 D(G(z)): 0.1098 / 0.0250\n",
            "[0/25][23/391] Loss_D: 0.2712 Loss_G: 4.7813 D(x): 0.9278 D(G(z)): 0.1633 / 0.0111\n",
            "[0/25][24/391] Loss_D: 0.4005 Loss_G: 2.8945 D(x): 0.7613 D(G(z)): 0.0708 / 0.0711\n",
            "[0/25][25/391] Loss_D: 0.4511 Loss_G: 5.8317 D(x): 0.9462 D(G(z)): 0.3058 / 0.0041\n",
            "[0/25][26/391] Loss_D: 0.3911 Loss_G: 3.8377 D(x): 0.7267 D(G(z)): 0.0241 / 0.0321\n",
            "[0/25][27/391] Loss_D: 0.1878 Loss_G: 3.8617 D(x): 0.9529 D(G(z)): 0.1232 / 0.0288\n",
            "[0/25][28/391] Loss_D: 0.2179 Loss_G: 4.7696 D(x): 0.9544 D(G(z)): 0.1491 / 0.0112\n",
            "[0/25][29/391] Loss_D: 0.1908 Loss_G: 4.3382 D(x): 0.8947 D(G(z)): 0.0665 / 0.0170\n",
            "[0/25][30/391] Loss_D: 0.2401 Loss_G: 4.0799 D(x): 0.8962 D(G(z)): 0.0981 / 0.0240\n",
            "[0/25][31/391] Loss_D: 0.3235 Loss_G: 4.2707 D(x): 0.8675 D(G(z)): 0.1408 / 0.0193\n",
            "[0/25][32/391] Loss_D: 0.3399 Loss_G: 4.2331 D(x): 0.8497 D(G(z)): 0.1394 / 0.0197\n",
            "[0/25][33/391] Loss_D: 0.3442 Loss_G: 3.9582 D(x): 0.8287 D(G(z)): 0.1186 / 0.0271\n",
            "[0/25][34/391] Loss_D: 0.2542 Loss_G: 5.8986 D(x): 0.9406 D(G(z)): 0.1635 / 0.0043\n",
            "[0/25][35/391] Loss_D: 0.3576 Loss_G: 3.1401 D(x): 0.7556 D(G(z)): 0.0367 / 0.0580\n",
            "[0/25][36/391] Loss_D: 0.5006 Loss_G: 8.4193 D(x): 0.9568 D(G(z)): 0.3310 / 0.0005\n",
            "[0/25][37/391] Loss_D: 0.7383 Loss_G: 3.8854 D(x): 0.5518 D(G(z)): 0.0024 / 0.0276\n",
            "[0/25][38/391] Loss_D: 0.2758 Loss_G: 5.4411 D(x): 0.9787 D(G(z)): 0.2069 / 0.0075\n",
            "[0/25][39/391] Loss_D: 0.2018 Loss_G: 5.5173 D(x): 0.9254 D(G(z)): 0.1072 / 0.0065\n",
            "[0/25][40/391] Loss_D: 0.2553 Loss_G: 5.4806 D(x): 0.8977 D(G(z)): 0.1144 / 0.0065\n",
            "[0/25][41/391] Loss_D: 0.3105 Loss_G: 4.5519 D(x): 0.8558 D(G(z)): 0.1116 / 0.0170\n",
            "[0/25][42/391] Loss_D: 0.4227 Loss_G: 5.2883 D(x): 0.8618 D(G(z)): 0.1953 / 0.0079\n",
            "[0/25][43/391] Loss_D: 0.4072 Loss_G: 5.0412 D(x): 0.8212 D(G(z)): 0.1479 / 0.0102\n",
            "[0/25][44/391] Loss_D: 0.3186 Loss_G: 4.0600 D(x): 0.8221 D(G(z)): 0.0899 / 0.0228\n",
            "[0/25][45/391] Loss_D: 0.4024 Loss_G: 6.3489 D(x): 0.8942 D(G(z)): 0.2266 / 0.0030\n",
            "[0/25][46/391] Loss_D: 0.3092 Loss_G: 4.3685 D(x): 0.7831 D(G(z)): 0.0267 / 0.0180\n",
            "[0/25][47/391] Loss_D: 0.3384 Loss_G: 6.2234 D(x): 0.9230 D(G(z)): 0.2041 / 0.0035\n",
            "[0/25][48/391] Loss_D: 0.1173 Loss_G: 5.9026 D(x): 0.9258 D(G(z)): 0.0266 / 0.0043\n",
            "[0/25][49/391] Loss_D: 0.1535 Loss_G: 4.5282 D(x): 0.9152 D(G(z)): 0.0542 / 0.0162\n",
            "[0/25][50/391] Loss_D: 0.1871 Loss_G: 5.7196 D(x): 0.9560 D(G(z)): 0.1252 / 0.0049\n",
            "[0/25][51/391] Loss_D: 0.1945 Loss_G: 5.2762 D(x): 0.9063 D(G(z)): 0.0658 / 0.0070\n",
            "[0/25][52/391] Loss_D: 0.2822 Loss_G: 5.7599 D(x): 0.8906 D(G(z)): 0.1307 / 0.0047\n",
            "[0/25][53/391] Loss_D: 0.3354 Loss_G: 4.0814 D(x): 0.8086 D(G(z)): 0.0785 / 0.0229\n",
            "[0/25][54/391] Loss_D: 0.3033 Loss_G: 7.8928 D(x): 0.9609 D(G(z)): 0.2115 / 0.0007\n",
            "[0/25][55/391] Loss_D: 0.1891 Loss_G: 6.5438 D(x): 0.8549 D(G(z)): 0.0112 / 0.0023\n",
            "[0/25][56/391] Loss_D: 0.1393 Loss_G: 5.0156 D(x): 0.9401 D(G(z)): 0.0685 / 0.0096\n",
            "[0/25][57/391] Loss_D: 0.3953 Loss_G: 7.9530 D(x): 0.9204 D(G(z)): 0.2328 / 0.0006\n",
            "[0/25][58/391] Loss_D: 0.2444 Loss_G: 5.9288 D(x): 0.8162 D(G(z)): 0.0078 / 0.0041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gMhxLnIeBfBe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}