{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Cwq-uPYvpa"
      },
      "source": [
        "# Build basic 2-Layer MLP to solve the xor-Problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "UZd3YQb5VW1c",
        "outputId": "1d116cdd-32a2-4a1e-d4d9-2bd27f287d24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1 MB 1.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.21.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.2.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K4FDsqgaYvps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs #for data generatio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2x1wijYZYvpu"
      },
      "outputs": [],
      "source": [
        "X, y = make_blobs(n_samples=200, n_features=2, cluster_std=.1\n",
        "                  ,centers= [(1,1), (1,0), (0,0),(0,1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aoAh4a4KYvpv"
      },
      "outputs": [],
      "source": [
        "y[y==2]=0\n",
        "y[y==3]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RMPaCrKBYvpw",
        "outputId": "916a2c65-1d72-4ae1-ae0c-701d25670eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f71b4b58f10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(X[:,0],X[:,1],c=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q9Y4g0NYvpy"
      },
      "source": [
        "## Steps:\n",
        "* build train and test sets\n",
        "* write MLP class in Pytorch with two layers with adjustable number of perceptrons\n",
        "* use nn.linear and nn.Sigmoid() units\n",
        "* train your model\n",
        "* test your model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "class MLP(torch.nn.Module): #all nets inherit from nn.Module\n",
        "    def __init__(self): #define layer types\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(2,4,bias=False) #1st layer input dim = 2, output =4 - | input needs to have size of data\n",
        "        self.fc2 = torch.nn.Linear(4,1,bias=False) #2nd layer input 4 out put 2 | output needs to be one for binary problem\n",
        "        self.non_linear = torch.nn.Sigmoid() #non-linear activation \n",
        "\n",
        "    def forward(self, x): #build network\n",
        "        output = self.fc1(x) #w*X\n",
        "        output = self.non_linear(output) # activation\n",
        "        output = self.fc2(output) #w*X\n",
        "        output = self.non_linear(output) # activation \n",
        "        return output"
      ],
      "metadata": {
        "id": "piXsTVTrZssQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split #for test set generation\n",
        "#split in train and test \n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#np->torch\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)\n"
      ],
      "metadata": {
        "id": "5YfSkNwwWZY1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "id": "QG5MeNZQXLuv",
        "outputId": "3ac0d3a1-8e6f-47ca-ef30-5d6264ba0a03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([134, 2]) torch.Size([134])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get instance of perceptron model\n",
        "model = MLP()\n",
        "\n",
        "#define loss function\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "#define optimizer -> SGD with learning rate lr\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "pDx8cyyzWhEB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show model\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bx3Btm46Ymq6",
        "outputId": "1791051f-706c-4b6d-a5bb-f221c7b8a96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=2, out_features=4, bias=False)\n",
            "  (fc2): Linear(in_features=4, out_features=1, bias=False)\n",
            "  (non_linear): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0NkfNJjKYmRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() #set to train mode\n",
        "iterations = 500\n",
        "for iter in range(iterations):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Iter {}: train loss: {}'.format(iter, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    #make gradient update\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "sYbJhiT3Wvgf",
        "outputId": "27b57a6a-b06c-4ef3-df8d-cd8e1a52a44a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: train loss: 0.7008231282234192\n",
            "Iter 1: train loss: 0.7007817029953003\n",
            "Iter 2: train loss: 0.7007405161857605\n",
            "Iter 3: train loss: 0.7006993889808655\n",
            "Iter 4: train loss: 0.7006590962409973\n",
            "Iter 5: train loss: 0.7006181478500366\n",
            "Iter 6: train loss: 0.700577974319458\n",
            "Iter 7: train loss: 0.7005379796028137\n",
            "Iter 8: train loss: 0.7004981637001038\n",
            "Iter 9: train loss: 0.7004583477973938\n",
            "Iter 10: train loss: 0.7004188299179077\n",
            "Iter 11: train loss: 0.7003799080848694\n",
            "Iter 12: train loss: 0.700340747833252\n",
            "Iter 13: train loss: 0.7003021240234375\n",
            "Iter 14: train loss: 0.700263500213623\n",
            "Iter 15: train loss: 0.7002254128456116\n",
            "Iter 16: train loss: 0.7001873254776001\n",
            "Iter 17: train loss: 0.7001492977142334\n",
            "Iter 18: train loss: 0.7001116275787354\n",
            "Iter 19: train loss: 0.7000740766525269\n",
            "Iter 20: train loss: 0.7000367641448975\n",
            "Iter 21: train loss: 0.6999996900558472\n",
            "Iter 22: train loss: 0.6999627947807312\n",
            "Iter 23: train loss: 0.6999263167381287\n",
            "Iter 24: train loss: 0.6998896598815918\n",
            "Iter 25: train loss: 0.6998535394668579\n",
            "Iter 26: train loss: 0.6998173594474792\n",
            "Iter 27: train loss: 0.6997813582420349\n",
            "Iter 28: train loss: 0.699745774269104\n",
            "Iter 29: train loss: 0.6997104287147522\n",
            "Iter 30: train loss: 0.6996750831604004\n",
            "Iter 31: train loss: 0.6996400356292725\n",
            "Iter 32: train loss: 0.6996051073074341\n",
            "Iter 33: train loss: 0.69957035779953\n",
            "Iter 34: train loss: 0.6995359063148499\n",
            "Iter 35: train loss: 0.6995016932487488\n",
            "Iter 36: train loss: 0.6994677186012268\n",
            "Iter 37: train loss: 0.6994336843490601\n",
            "Iter 38: train loss: 0.6994001269340515\n",
            "Iter 39: train loss: 0.6993666291236877\n",
            "Iter 40: train loss: 0.699333131313324\n",
            "Iter 41: train loss: 0.6992999315261841\n",
            "Iter 42: train loss: 0.6992668509483337\n",
            "Iter 43: train loss: 0.6992339491844177\n",
            "Iter 44: train loss: 0.6992015838623047\n",
            "Iter 45: train loss: 0.6991689205169678\n",
            "Iter 46: train loss: 0.6991367340087891\n",
            "Iter 47: train loss: 0.6991045475006104\n",
            "Iter 48: train loss: 0.699073076248169\n",
            "Iter 49: train loss: 0.6990410089492798\n",
            "Iter 50: train loss: 0.6990098357200623\n",
            "Iter 51: train loss: 0.6989785432815552\n",
            "Iter 52: train loss: 0.6989472508430481\n",
            "Iter 53: train loss: 0.6989160776138306\n",
            "Iter 54: train loss: 0.6988851428031921\n",
            "Iter 55: train loss: 0.6988544464111328\n",
            "Iter 56: train loss: 0.6988239884376526\n",
            "Iter 57: train loss: 0.6987935900688171\n",
            "Iter 58: train loss: 0.6987634897232056\n",
            "Iter 59: train loss: 0.6987336277961731\n",
            "Iter 60: train loss: 0.6987035870552063\n",
            "Iter 61: train loss: 0.6986740827560425\n",
            "Iter 62: train loss: 0.6986446380615234\n",
            "Iter 63: train loss: 0.6986152529716492\n",
            "Iter 64: train loss: 0.6985861659049988\n",
            "Iter 65: train loss: 0.6985569596290588\n",
            "Iter 66: train loss: 0.6985280513763428\n",
            "Iter 67: train loss: 0.6984994411468506\n",
            "Iter 68: train loss: 0.6984710693359375\n",
            "Iter 69: train loss: 0.6984425187110901\n",
            "Iter 70: train loss: 0.6984142065048218\n",
            "Iter 71: train loss: 0.6983863115310669\n",
            "Iter 72: train loss: 0.6983581781387329\n",
            "Iter 73: train loss: 0.6983305215835571\n",
            "Iter 74: train loss: 0.6983028650283813\n",
            "Iter 75: train loss: 0.6982755661010742\n",
            "Iter 76: train loss: 0.698248028755188\n",
            "Iter 77: train loss: 0.6982212662696838\n",
            "Iter 78: train loss: 0.6981942057609558\n",
            "Iter 79: train loss: 0.698167085647583\n",
            "Iter 80: train loss: 0.6981403827667236\n",
            "Iter 81: train loss: 0.6981140375137329\n",
            "Iter 82: train loss: 0.6980873346328735\n",
            "Iter 83: train loss: 0.6980611681938171\n",
            "Iter 84: train loss: 0.6980352401733398\n",
            "Iter 85: train loss: 0.6980093121528625\n",
            "Iter 86: train loss: 0.6979835629463196\n",
            "Iter 87: train loss: 0.6979578733444214\n",
            "Iter 88: train loss: 0.697932243347168\n",
            "Iter 89: train loss: 0.6979068517684937\n",
            "Iter 90: train loss: 0.6978817582130432\n",
            "Iter 91: train loss: 0.6978564262390137\n",
            "Iter 92: train loss: 0.6978315711021423\n",
            "Iter 93: train loss: 0.6978067755699158\n",
            "Iter 94: train loss: 0.6977819800376892\n",
            "Iter 95: train loss: 0.6977574825286865\n",
            "Iter 96: train loss: 0.6977329254150391\n",
            "Iter 97: train loss: 0.6977087259292603\n",
            "Iter 98: train loss: 0.6976844668388367\n",
            "Iter 99: train loss: 0.6976608037948608\n",
            "Iter 100: train loss: 0.6976367831230164\n",
            "Iter 101: train loss: 0.6976132988929749\n",
            "Iter 102: train loss: 0.6975892186164856\n",
            "Iter 103: train loss: 0.6975657939910889\n",
            "Iter 104: train loss: 0.6975426077842712\n",
            "Iter 105: train loss: 0.6975193023681641\n",
            "Iter 106: train loss: 0.697496235370636\n",
            "Iter 107: train loss: 0.6974731683731079\n",
            "Iter 108: train loss: 0.6974503397941589\n",
            "Iter 109: train loss: 0.6974277496337891\n",
            "Iter 110: train loss: 0.6974051594734192\n",
            "Iter 111: train loss: 0.6973826885223389\n",
            "Iter 112: train loss: 0.6973603963851929\n",
            "Iter 113: train loss: 0.6973382234573364\n",
            "Iter 114: train loss: 0.69731605052948\n",
            "Iter 115: train loss: 0.6972942352294922\n",
            "Iter 116: train loss: 0.6972722411155701\n",
            "Iter 117: train loss: 0.6972503662109375\n",
            "Iter 118: train loss: 0.6972289681434631\n",
            "Iter 119: train loss: 0.697207510471344\n",
            "Iter 120: train loss: 0.6971863508224487\n",
            "Iter 121: train loss: 0.6971650123596191\n",
            "Iter 122: train loss: 0.6971437335014343\n",
            "Iter 123: train loss: 0.6971228122711182\n",
            "Iter 124: train loss: 0.6971019506454468\n",
            "Iter 125: train loss: 0.6970809102058411\n",
            "Iter 126: train loss: 0.6970602869987488\n",
            "Iter 127: train loss: 0.6970400214195251\n",
            "Iter 128: train loss: 0.6970193386077881\n",
            "Iter 129: train loss: 0.6969989538192749\n",
            "Iter 130: train loss: 0.6969790458679199\n",
            "Iter 131: train loss: 0.6969590187072754\n",
            "Iter 132: train loss: 0.6969390511512756\n",
            "Iter 133: train loss: 0.6969188451766968\n",
            "Iter 134: train loss: 0.6968993544578552\n",
            "Iter 135: train loss: 0.6968796849250793\n",
            "Iter 136: train loss: 0.696860134601593\n",
            "Iter 137: train loss: 0.6968408226966858\n",
            "Iter 138: train loss: 0.6968212723731995\n",
            "Iter 139: train loss: 0.6968019604682922\n",
            "Iter 140: train loss: 0.6967827677726746\n",
            "Iter 141: train loss: 0.6967637538909912\n",
            "Iter 142: train loss: 0.696744978427887\n",
            "Iter 143: train loss: 0.696726381778717\n",
            "Iter 144: train loss: 0.696707546710968\n",
            "Iter 145: train loss: 0.6966889500617981\n",
            "Iter 146: train loss: 0.6966705322265625\n",
            "Iter 147: train loss: 0.6966521143913269\n",
            "Iter 148: train loss: 0.6966337561607361\n",
            "Iter 149: train loss: 0.6966156959533691\n",
            "Iter 150: train loss: 0.6965974569320679\n",
            "Iter 151: train loss: 0.6965796947479248\n",
            "Iter 152: train loss: 0.696561872959137\n",
            "Iter 153: train loss: 0.6965438723564148\n",
            "Iter 154: train loss: 0.6965265274047852\n",
            "Iter 155: train loss: 0.6965088248252869\n",
            "Iter 156: train loss: 0.6964911818504333\n",
            "Iter 157: train loss: 0.6964741945266724\n",
            "Iter 158: train loss: 0.6964566707611084\n",
            "Iter 159: train loss: 0.6964395046234131\n",
            "Iter 160: train loss: 0.6964223384857178\n",
            "Iter 161: train loss: 0.696405291557312\n",
            "Iter 162: train loss: 0.6963886022567749\n",
            "Iter 163: train loss: 0.6963717341423035\n",
            "Iter 164: train loss: 0.6963549852371216\n",
            "Iter 165: train loss: 0.6963380575180054\n",
            "Iter 166: train loss: 0.6963219046592712\n",
            "Iter 167: train loss: 0.6963055729866028\n",
            "Iter 168: train loss: 0.6962889432907104\n",
            "Iter 169: train loss: 0.6962726712226868\n",
            "Iter 170: train loss: 0.696256697177887\n",
            "Iter 171: train loss: 0.6962404847145081\n",
            "Iter 172: train loss: 0.6962246894836426\n",
            "Iter 173: train loss: 0.6962084770202637\n",
            "Iter 174: train loss: 0.696192741394043\n",
            "Iter 175: train loss: 0.6961771845817566\n",
            "Iter 176: train loss: 0.6961615085601807\n",
            "Iter 177: train loss: 0.6961457133293152\n",
            "Iter 178: train loss: 0.6961304545402527\n",
            "Iter 179: train loss: 0.6961148977279663\n",
            "Iter 180: train loss: 0.6961000561714172\n",
            "Iter 181: train loss: 0.6960844397544861\n",
            "Iter 182: train loss: 0.6960693597793579\n",
            "Iter 183: train loss: 0.6960545182228088\n",
            "Iter 184: train loss: 0.6960391998291016\n",
            "Iter 185: train loss: 0.6960244178771973\n",
            "Iter 186: train loss: 0.6960099339485168\n",
            "Iter 187: train loss: 0.6959952712059021\n",
            "Iter 188: train loss: 0.6959802508354187\n",
            "Iter 189: train loss: 0.6959658265113831\n",
            "Iter 190: train loss: 0.6959514617919922\n",
            "Iter 191: train loss: 0.6959369778633118\n",
            "Iter 192: train loss: 0.6959227323532104\n",
            "Iter 193: train loss: 0.6959084272384644\n",
            "Iter 194: train loss: 0.695894181728363\n",
            "Iter 195: train loss: 0.6958802342414856\n",
            "Iter 196: train loss: 0.6958662867546082\n",
            "Iter 197: train loss: 0.695852518081665\n",
            "Iter 198: train loss: 0.6958385705947876\n",
            "Iter 199: train loss: 0.695824921131134\n",
            "Iter 200: train loss: 0.6958110332489014\n",
            "Iter 201: train loss: 0.6957976222038269\n",
            "Iter 202: train loss: 0.6957837343215942\n",
            "Iter 203: train loss: 0.6957703828811646\n",
            "Iter 204: train loss: 0.6957572102546692\n",
            "Iter 205: train loss: 0.6957437992095947\n",
            "Iter 206: train loss: 0.6957305669784546\n",
            "Iter 207: train loss: 0.6957175135612488\n",
            "Iter 208: train loss: 0.6957044005393982\n",
            "Iter 209: train loss: 0.6956914663314819\n",
            "Iter 210: train loss: 0.6956782341003418\n",
            "Iter 211: train loss: 0.6956654191017151\n",
            "Iter 212: train loss: 0.6956526637077332\n",
            "Iter 213: train loss: 0.6956399083137512\n",
            "Iter 214: train loss: 0.6956272721290588\n",
            "Iter 215: train loss: 0.6956148147583008\n",
            "Iter 216: train loss: 0.6956021785736084\n",
            "Iter 217: train loss: 0.6955897808074951\n",
            "Iter 218: train loss: 0.6955774426460266\n",
            "Iter 219: train loss: 0.6955649256706238\n",
            "Iter 220: train loss: 0.6955526471138\n",
            "Iter 221: train loss: 0.6955407857894897\n",
            "Iter 222: train loss: 0.6955286264419556\n",
            "Iter 223: train loss: 0.6955163478851318\n",
            "Iter 224: train loss: 0.6955044865608215\n",
            "Iter 225: train loss: 0.695492684841156\n",
            "Iter 226: train loss: 0.6954805850982666\n",
            "Iter 227: train loss: 0.6954690217971802\n",
            "Iter 228: train loss: 0.6954572200775146\n",
            "Iter 229: train loss: 0.6954456567764282\n",
            "Iter 230: train loss: 0.6954339742660522\n",
            "Iter 231: train loss: 0.6954224109649658\n",
            "Iter 232: train loss: 0.6954110264778137\n",
            "Iter 233: train loss: 0.695399820804596\n",
            "Iter 234: train loss: 0.6953884363174438\n",
            "Iter 235: train loss: 0.6953772306442261\n",
            "Iter 236: train loss: 0.6953655481338501\n",
            "Iter 237: train loss: 0.6953547596931458\n",
            "Iter 238: train loss: 0.6953437328338623\n",
            "Iter 239: train loss: 0.6953327655792236\n",
            "Iter 240: train loss: 0.695321798324585\n",
            "Iter 241: train loss: 0.6953107118606567\n",
            "Iter 242: train loss: 0.6952999830245972\n",
            "Iter 243: train loss: 0.6952890157699585\n",
            "Iter 244: train loss: 0.6952782869338989\n",
            "Iter 245: train loss: 0.6952678561210632\n",
            "Iter 246: train loss: 0.6952571868896484\n",
            "Iter 247: train loss: 0.6952465772628784\n",
            "Iter 248: train loss: 0.6952359676361084\n",
            "Iter 249: train loss: 0.6952260136604309\n",
            "Iter 250: train loss: 0.6952154636383057\n",
            "Iter 251: train loss: 0.6952053904533386\n",
            "Iter 252: train loss: 0.6951949000358582\n",
            "Iter 253: train loss: 0.6951845288276672\n",
            "Iter 254: train loss: 0.6951745748519897\n",
            "Iter 255: train loss: 0.6951646208763123\n",
            "Iter 256: train loss: 0.6951544284820557\n",
            "Iter 257: train loss: 0.6951444745063782\n",
            "Iter 258: train loss: 0.6951345801353455\n",
            "Iter 259: train loss: 0.6951245665550232\n",
            "Iter 260: train loss: 0.6951149106025696\n",
            "Iter 261: train loss: 0.6951051950454712\n",
            "Iter 262: train loss: 0.6950953006744385\n",
            "Iter 263: train loss: 0.6950860619544983\n",
            "Iter 264: train loss: 0.6950762271881104\n",
            "Iter 265: train loss: 0.6950668096542358\n",
            "Iter 266: train loss: 0.6950569748878479\n",
            "Iter 267: train loss: 0.6950477957725525\n",
            "Iter 268: train loss: 0.6950384974479675\n",
            "Iter 269: train loss: 0.6950288414955139\n",
            "Iter 270: train loss: 0.6950197815895081\n",
            "Iter 271: train loss: 0.6950104236602783\n",
            "Iter 272: train loss: 0.6950014233589172\n",
            "Iter 273: train loss: 0.6949922442436218\n",
            "Iter 274: train loss: 0.6949830651283264\n",
            "Iter 275: train loss: 0.694973886013031\n",
            "Iter 276: train loss: 0.6949652433395386\n",
            "Iter 277: train loss: 0.6949564218521118\n",
            "Iter 278: train loss: 0.6949474811553955\n",
            "Iter 279: train loss: 0.6949385404586792\n",
            "Iter 280: train loss: 0.6949297785758972\n",
            "Iter 281: train loss: 0.6949211955070496\n",
            "Iter 282: train loss: 0.6949121952056885\n",
            "Iter 283: train loss: 0.6949038505554199\n",
            "Iter 284: train loss: 0.6948952078819275\n",
            "Iter 285: train loss: 0.6948866844177246\n",
            "Iter 286: train loss: 0.694878101348877\n",
            "Iter 287: train loss: 0.6948696970939636\n",
            "Iter 288: train loss: 0.6948612928390503\n",
            "Iter 289: train loss: 0.6948530077934265\n",
            "Iter 290: train loss: 0.6948445439338684\n",
            "Iter 291: train loss: 0.6948363184928894\n",
            "Iter 292: train loss: 0.6948282122612\n",
            "Iter 293: train loss: 0.6948201060295105\n",
            "Iter 294: train loss: 0.694811999797821\n",
            "Iter 295: train loss: 0.6948040723800659\n",
            "Iter 296: train loss: 0.6947957873344421\n",
            "Iter 297: train loss: 0.6947877407073975\n",
            "Iter 298: train loss: 0.6947796940803528\n",
            "Iter 299: train loss: 0.6947720050811768\n",
            "Iter 300: train loss: 0.6947638392448425\n",
            "Iter 301: train loss: 0.6947562098503113\n",
            "Iter 302: train loss: 0.6947484612464905\n",
            "Iter 303: train loss: 0.6947406530380249\n",
            "Iter 304: train loss: 0.6947330832481384\n",
            "Iter 305: train loss: 0.6947256326675415\n",
            "Iter 306: train loss: 0.6947175860404968\n",
            "Iter 307: train loss: 0.6947104334831238\n",
            "Iter 308: train loss: 0.6947028636932373\n",
            "Iter 309: train loss: 0.6946951746940613\n",
            "Iter 310: train loss: 0.6946879029273987\n",
            "Iter 311: train loss: 0.6946804523468018\n",
            "Iter 312: train loss: 0.6946728825569153\n",
            "Iter 313: train loss: 0.6946659088134766\n",
            "Iter 314: train loss: 0.6946585178375244\n",
            "Iter 315: train loss: 0.6946512460708618\n",
            "Iter 316: train loss: 0.6946439743041992\n",
            "Iter 317: train loss: 0.69463711977005\n",
            "Iter 318: train loss: 0.694629967212677\n",
            "Iter 319: train loss: 0.6946225762367249\n",
            "Iter 320: train loss: 0.6946158409118652\n",
            "Iter 321: train loss: 0.6946086883544922\n",
            "Iter 322: train loss: 0.6946014761924744\n",
            "Iter 323: train loss: 0.69459468126297\n",
            "Iter 324: train loss: 0.6945878863334656\n",
            "Iter 325: train loss: 0.6945812702178955\n",
            "Iter 326: train loss: 0.6945743560791016\n",
            "Iter 327: train loss: 0.6945675015449524\n",
            "Iter 328: train loss: 0.6945607662200928\n",
            "Iter 329: train loss: 0.6945542097091675\n",
            "Iter 330: train loss: 0.6945474147796631\n",
            "Iter 331: train loss: 0.6945409178733826\n",
            "Iter 332: train loss: 0.6945343613624573\n",
            "Iter 333: train loss: 0.6945278644561768\n",
            "Iter 334: train loss: 0.6945210695266724\n",
            "Iter 335: train loss: 0.6945146918296814\n",
            "Iter 336: train loss: 0.6945083141326904\n",
            "Iter 337: train loss: 0.6945019364356995\n",
            "Iter 338: train loss: 0.6944957375526428\n",
            "Iter 339: train loss: 0.6944890022277832\n",
            "Iter 340: train loss: 0.6944828033447266\n",
            "Iter 341: train loss: 0.6944766044616699\n",
            "Iter 342: train loss: 0.694470226764679\n",
            "Iter 343: train loss: 0.6944641470909119\n",
            "Iter 344: train loss: 0.6944579482078552\n",
            "Iter 345: train loss: 0.6944519281387329\n",
            "Iter 346: train loss: 0.694445788860321\n",
            "Iter 347: train loss: 0.6944398283958435\n",
            "Iter 348: train loss: 0.6944336891174316\n",
            "Iter 349: train loss: 0.6944275498390198\n",
            "Iter 350: train loss: 0.6944218873977661\n",
            "Iter 351: train loss: 0.6944159269332886\n",
            "Iter 352: train loss: 0.6944096088409424\n",
            "Iter 353: train loss: 0.6944039463996887\n",
            "Iter 354: train loss: 0.6943982839584351\n",
            "Iter 355: train loss: 0.6943925023078918\n",
            "Iter 356: train loss: 0.6943867206573486\n",
            "Iter 357: train loss: 0.6943808794021606\n",
            "Iter 358: train loss: 0.6943750977516174\n",
            "Iter 359: train loss: 0.6943695545196533\n",
            "Iter 360: train loss: 0.6943635940551758\n",
            "Iter 361: train loss: 0.6943581700325012\n",
            "Iter 362: train loss: 0.6943526864051819\n",
            "Iter 363: train loss: 0.6943469047546387\n",
            "Iter 364: train loss: 0.6943415999412537\n",
            "Iter 365: train loss: 0.6943358778953552\n",
            "Iter 366: train loss: 0.6943305134773254\n",
            "Iter 367: train loss: 0.6943250894546509\n",
            "Iter 368: train loss: 0.6943198442459106\n",
            "Iter 369: train loss: 0.6943145990371704\n",
            "Iter 370: train loss: 0.6943090558052063\n",
            "Iter 371: train loss: 0.694303572177887\n",
            "Iter 372: train loss: 0.6942984461784363\n",
            "Iter 373: train loss: 0.6942933201789856\n",
            "Iter 374: train loss: 0.6942882537841797\n",
            "Iter 375: train loss: 0.6942830085754395\n",
            "Iter 376: train loss: 0.6942777633666992\n",
            "Iter 377: train loss: 0.6942726373672485\n",
            "Iter 378: train loss: 0.6942672729492188\n",
            "Iter 379: train loss: 0.6942621469497681\n",
            "Iter 380: train loss: 0.6942571997642517\n",
            "Iter 381: train loss: 0.6942521333694458\n",
            "Iter 382: train loss: 0.694247305393219\n",
            "Iter 383: train loss: 0.6942421793937683\n",
            "Iter 384: train loss: 0.694237232208252\n",
            "Iter 385: train loss: 0.6942322850227356\n",
            "Iter 386: train loss: 0.6942276358604431\n",
            "Iter 387: train loss: 0.6942223310470581\n",
            "Iter 388: train loss: 0.6942179203033447\n",
            "Iter 389: train loss: 0.6942129135131836\n",
            "Iter 390: train loss: 0.6942081451416016\n",
            "Iter 391: train loss: 0.69420325756073\n",
            "Iter 392: train loss: 0.694198727607727\n",
            "Iter 393: train loss: 0.6941937804222107\n",
            "Iter 394: train loss: 0.694189190864563\n",
            "Iter 395: train loss: 0.6941847205162048\n",
            "Iter 396: train loss: 0.6941799521446228\n",
            "Iter 397: train loss: 0.6941754221916199\n",
            "Iter 398: train loss: 0.6941708922386169\n",
            "Iter 399: train loss: 0.6941663026809692\n",
            "Iter 400: train loss: 0.6941618323326111\n",
            "Iter 401: train loss: 0.6941571235656738\n",
            "Iter 402: train loss: 0.6941527724266052\n",
            "Iter 403: train loss: 0.6941482424736023\n",
            "Iter 404: train loss: 0.6941437721252441\n",
            "Iter 405: train loss: 0.6941396594047546\n",
            "Iter 406: train loss: 0.6941348910331726\n",
            "Iter 407: train loss: 0.6941306591033936\n",
            "Iter 408: train loss: 0.6941264867782593\n",
            "Iter 409: train loss: 0.6941218376159668\n",
            "Iter 410: train loss: 0.6941176056861877\n",
            "Iter 411: train loss: 0.6941134333610535\n",
            "Iter 412: train loss: 0.6941091418266296\n",
            "Iter 413: train loss: 0.6941049695014954\n",
            "Iter 414: train loss: 0.6941006779670715\n",
            "Iter 415: train loss: 0.6940967440605164\n",
            "Iter 416: train loss: 0.6940922737121582\n",
            "Iter 417: train loss: 0.6940884590148926\n",
            "Iter 418: train loss: 0.6940842270851135\n",
            "Iter 419: train loss: 0.6940800547599792\n",
            "Iter 420: train loss: 0.694075882434845\n",
            "Iter 421: train loss: 0.6940721273422241\n",
            "Iter 422: train loss: 0.6940678358078003\n",
            "Iter 423: train loss: 0.6940640807151794\n",
            "Iter 424: train loss: 0.6940600872039795\n",
            "Iter 425: train loss: 0.6940557956695557\n",
            "Iter 426: train loss: 0.6940522193908691\n",
            "Iter 427: train loss: 0.6940481066703796\n",
            "Iter 428: train loss: 0.6940442323684692\n",
            "Iter 429: train loss: 0.6940402984619141\n",
            "Iter 430: train loss: 0.6940366625785828\n",
            "Iter 431: train loss: 0.6940326690673828\n",
            "Iter 432: train loss: 0.6940288543701172\n",
            "Iter 433: train loss: 0.6940249800682068\n",
            "Iter 434: train loss: 0.6940214037895203\n",
            "Iter 435: train loss: 0.6940176486968994\n",
            "Iter 436: train loss: 0.6940138936042786\n",
            "Iter 437: train loss: 0.6940104365348816\n",
            "Iter 438: train loss: 0.6940065622329712\n",
            "Iter 439: train loss: 0.6940029263496399\n",
            "Iter 440: train loss: 0.6939991116523743\n",
            "Iter 441: train loss: 0.6939956545829773\n",
            "Iter 442: train loss: 0.6939918994903564\n",
            "Iter 443: train loss: 0.6939883232116699\n",
            "Iter 444: train loss: 0.6939848065376282\n",
            "Iter 445: train loss: 0.6939809918403625\n",
            "Iter 446: train loss: 0.6939776539802551\n",
            "Iter 447: train loss: 0.6939740777015686\n",
            "Iter 448: train loss: 0.6939709186553955\n",
            "Iter 449: train loss: 0.6939670443534851\n",
            "Iter 450: train loss: 0.6939637064933777\n",
            "Iter 451: train loss: 0.6939603686332703\n",
            "Iter 452: train loss: 0.6939569711685181\n",
            "Iter 453: train loss: 0.6939533948898315\n",
            "Iter 454: train loss: 0.6939501166343689\n",
            "Iter 455: train loss: 0.6939468383789062\n",
            "Iter 456: train loss: 0.6939436793327332\n",
            "Iter 457: train loss: 0.693940281867981\n",
            "Iter 458: train loss: 0.6939369440078735\n",
            "Iter 459: train loss: 0.6939334273338318\n",
            "Iter 460: train loss: 0.6939302086830139\n",
            "Iter 461: train loss: 0.693926990032196\n",
            "Iter 462: train loss: 0.693923830986023\n",
            "Iter 463: train loss: 0.6939207315444946\n",
            "Iter 464: train loss: 0.6939172744750977\n",
            "Iter 465: train loss: 0.6939142346382141\n",
            "Iter 466: train loss: 0.6939111948013306\n",
            "Iter 467: train loss: 0.6939079165458679\n",
            "Iter 468: train loss: 0.6939046382904053\n",
            "Iter 469: train loss: 0.6939017176628113\n",
            "Iter 470: train loss: 0.6938984394073486\n",
            "Iter 471: train loss: 0.6938954591751099\n",
            "Iter 472: train loss: 0.6938920021057129\n",
            "Iter 473: train loss: 0.6938892602920532\n",
            "Iter 474: train loss: 0.6938865184783936\n",
            "Iter 475: train loss: 0.6938832402229309\n",
            "Iter 476: train loss: 0.6938803195953369\n",
            "Iter 477: train loss: 0.6938772797584534\n",
            "Iter 478: train loss: 0.6938743591308594\n",
            "Iter 479: train loss: 0.6938712000846863\n",
            "Iter 480: train loss: 0.6938683390617371\n",
            "Iter 481: train loss: 0.6938655972480774\n",
            "Iter 482: train loss: 0.6938624978065491\n",
            "Iter 483: train loss: 0.693859875202179\n",
            "Iter 484: train loss: 0.6938567161560059\n",
            "Iter 485: train loss: 0.6938538551330566\n",
            "Iter 486: train loss: 0.6938513517379761\n",
            "Iter 487: train loss: 0.693848192691803\n",
            "Iter 488: train loss: 0.6938453316688538\n",
            "Iter 489: train loss: 0.6938426494598389\n",
            "Iter 490: train loss: 0.693839967250824\n",
            "Iter 491: train loss: 0.6938371062278748\n",
            "Iter 492: train loss: 0.6938341856002808\n",
            "Iter 493: train loss: 0.6938318014144897\n",
            "Iter 494: train loss: 0.6938289403915405\n",
            "Iter 495: train loss: 0.6938260793685913\n",
            "Iter 496: train loss: 0.6938236355781555\n",
            "Iter 497: train loss: 0.6938207745552063\n",
            "Iter 498: train loss: 0.6938183307647705\n",
            "Iter 499: train loss: 0.6938155293464661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test \n",
        "y_pred = model(x_test) #predict\n",
        "y_pred=(y_pred>0.5).int().flatten() #argmax class lable\n",
        "test_acc = y_test.shape[0]/torch.sum(y_pred == y_test.int()) #check result: devide num of samples by num of correct ones, need to cast to int\n",
        "print(\"test ACC: \",test_acc.float())"
      ],
      "metadata": {
        "id": "AKqld7MKW61e",
        "outputId": "11e9d0c1-37d9-4f1a-fa00-7fa5d20490ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test ACC:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a34SBiPJZMbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Assignment_Basic_MLP_in_Pytorch.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}