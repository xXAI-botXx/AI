{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySpyYOfrOLO7"
      },
      "source": [
        "#### Install PyTorch\n",
        "PyTorch (from Facebook) is NOT pre-installed on Googles CoLab "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PTBwCwiqOLPC",
        "outputId": "d1d76506-3296-47a5-b8d0-48f21154b945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1 MB 1.6 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.2.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGSzk158OLPE"
      },
      "source": [
        "# A Perceptron in PyTorch\n",
        "implementing our Numpy model with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WatAvKJiOLPG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs #for data generation\n",
        "from sklearn.model_selection import train_test_split #for test set generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NSrCnGPcOLPH"
      },
      "outputs": [],
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2, n_features=2,center_box=(2,10),random_state=42)\n",
        "#y=y*2-1 #rescale to [-1,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uxw_t5YeOLPI",
        "outputId": "089dead2-02be-4260-d69c-0e6df8a6722d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fd656252190>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydZ3hU1daA33WmZZIQSAhNuo1PUVHBgoqCWK8KFlCxXMXCtV57L9i7XgvqFUWwooKNqyiKiCgiRRSUoiBKE+mQOn19P06IKZNkksxkJsl+n+c8kH3O2XtNYNZZZ+1VRFUxGAwGQ8NjJVsAg8FgaK4YBWwwGAxJwihgg8FgSBJGARsMBkOSMArYYDAYkoRRwAaDwZAkjAI2GAyGGBCRl0Vkg4j8XMV5EZGnRWS5iCwUkf1rmtMoYIPBYIiNccBx1Zw/Htit5BgBPF/ThEYBGwwGQwyo6gxgSzWXDAZeVZvvgFYi0qG6OZ3xFLAmcnNztVu3bg25pMFgaKR8//33m1S1TX3mOHZAhm7eEq55rYX+RYCvzNBoVR1dy+U6AqvL/LymZGxdVTc0qALu1q0b8+bNa8glDQZDI0VEVtZ3js1bwsyZ0qXG6xwdlvlUtU9916stDaqADQaDoSFRIEKkoZZbC3Qu83OnkrEqMT5gg8HQZFGUoIZrPOLEJOCfJdEQBwPbVbVK9wMYC9hgMDRx4mUBi8h4oD+QKyJrgJGAC0BV/wtMBv4BLAeKgOE1zWkUsMFgaLIoSjhOJXdVdVgN5xW4vDZzGgWc4gR8AX79fgXpLbx037sLIpJskQyGRkWE1K15bhRwCvPFm1/z1CWjEUuIhCO03imH+z++hY67VhtaaDAYSlAgnMIK2GzCpSi/LfiD/4z4L8UFPoryivEV+vlz+V/ceNQ9RCINtqtrMDR6ImiNR7IwCjhF+d/zUwj6Q+XGVJX8rQUsmvlLkqQyGBoXCgRVazyShXFBpChb/tpGJFzZ0hURtm/KS4JEBkPjQ1HjgjDUnoNP6E1auqfSeDAQouchPZIgkcHQCFEIx3AkC6OAU5SB5/Sj/c5t8XjdpWNpGR5Ov34Q2e1aJVEyg6HxYGfC1XwkC+OCSFE8Xg9Pz3qAj1/4nBkTZ5GZncHgy47joBN6J1s0g6ERIYRJ3dBNo4BTGG9GGkOuPYkh156UbFEMhkaJvQlnFLAhBVBVfIU+POkeLMt4nwxNHzsOOHUVsPkWNhM+GfMFQ9tfxCk553Na7gW889gkNIbwG1+Rn2XzV7Dpz+rqUBsMqUtEpcYjWRgLuBkwbfw3PHvVWPxFfgAKthXy2t3vIBYMvXZQlfdNfOJ/vDLybSyHRTAQYt8Be3Hb+KvJyEpvKNENhnphLGBD0nll5NulyncHvkI/4x94v0or+NtJc3ll5Nv4Cv0U5RUT9AX5cdpPPHTuMw0hssEQFxQhjFXjkSyMAm4GbFy9Oep44bZCgv5g1HNvP/IhvsLySjvoD/H9ZwvYtnF73GU0GBJFKrsgjAJuBnTusVPU8ez2rXB5XFHPbVm3Neq4w+Ugb3NB3GQzGBKJIgTUUeORLIwCbgZc/Mi55RI6ADzpbi56+Jwqy1vuN3BvHM7K/z0cDouddmmXEDkNhnhjJ2JYNR7JosaVReRlEdkgIj+XGRsqIotEJCIiDd7IzlA7+hzTi7s/uJHd9t8ZT7qHrnt24qZX/81RZx9e5T3n3H4a6VnpOFx/WweedDeX/ud8nK7Y9m6XzV/BJ2O+4McvfzYV3AxJI1ySjFHdkSxi+SaNA0YBr5YZ+xk4FXghATIZEkDvo3vR++heMV/ftksbXvjxMd56+AN+/PJn2nbJ5YwbBrPvgL1qvDfgD3LHSQ+x6Fu7aptlCa075vDE9LtNGrWhQVEVwpq6L/o1KmBVnSEi3SqMLQFMd4YmTptOrbnymQtrfd+b97/LzzOXEigOlI6t+209j17wHA98fGs8RTQYaiSSwmFoCY8DFpERwAiALl26JHo5Qwrw6Zhp5ZQvQDgUZv7UhfiK/FGrvBkMicDehEvddIeE2+aqOlpV+6hqnzZt2iR6OUMKEAyEqjwXDlZ9zmCIN41+E85gqC2HDO5TbvNuB916diajZUYSJDI0Z8IqNR7JwihgQ9y54P6zyGnfirQM29Xg9rpJz/Jyw9hadew2GOpNqmfC1egcEZHxQH8gV0TWACOBLcAzQBvgYxH5UVWPTaSghsZDdrtWjFn8JNPe+Jols5fRucdOHDt8AK3atEy2aIZmSKSRR0EMq+LU+3GWxdCE8GakccKIozlhxNHJFsXQjLGL8TRiBWwwGAyNFUUIJjHVuCaMAm5kLJ2zjNfunsAfi1bTrWdnzh05lP87cLdki2UwpCSqNO5EDEPqsGD6Im474QH8JTG2G1ZtYsH0Rdz30S01Zqj5ivzkbykgp0MrHI7UtQgMhvgiKZ2IkbqPBkMlnr3q5VLluwN/cYDnrhlb5T0Bf5D/jPgvp+UOZ3iPf3N6+4uY8sqXpedVtcqawMUFxSyds4wNqzbG5wMYDA2MYlvANR3JwljAjYg/Fq2OPv5z9HGApy9/kS/HzyTgs+v++osDPHP5GCyxmP7OTL7/bAGWw6LfaQdz+dMXkJXTAoC3H/mA1+6egMPlIBQIsechPRg58XoyW5k4XkPjIpU34VJXMkMlWmRnRh3Pyok+XphXxLQ3v6mUFuwv8vP4xc8zb8oCwqEIQX+IGRNmce0RI4lEIsz8YA6v3TMRf3GAorxiAr4gP3+zlAfOfiounyNvcz6jb3yV83v8mysOvoVp47+JqT+dwVBblJqLsZuecIaYGHr9IF6/d2K59kKedA9Drovetn7bhu04HBbRel6EQ2H7/ayEUDDMhpUb+XHaz7zz2KRKLYxCgRA/TvuZrRu2k9227vG8hdsLuWT/G9i2fntpyvJ/RvyXZfNX8K9H/1nneQ2GaNht6VNXzRkLuBFx+g2DGHTZsXi8bryZaXi8bgZfcRyn3zA46vVtu+RiOaL8EwvllO8OwqEwq5asZetf26LO53Q5yNucX49PAB+/OJW8Tfnl6kX4Cv18OOpTtvwVvQuHwVB3aq4FnMx6wCmpgMOhMAumL2L25PkU5RcnW5yUwbIsRjxyLhM2jOG5eQ8zYcMYLn7oHCwr+j+jy+1i+H1n4ilTfUxEcLmduNPdla53OB107dmJ3sfsg8NZOVLCclp03LV9vT7D/M8XVtpIBHB5nCz7fkW95jYYKqLYmXA1Hcki5WzzZfNXcOvx99ubRgLhYJgrRl3IccOPTLZoKYM3I41Ou0fv81aRk6/4B613as2b97/LprVb2LPv7px126ncOehhtvlDRMJ2pwqn20mHndux74C96NxjJ2ZM+I6ivCJCwTBguzouf+qCmLthVEXbrm2wHFbpujuIhCPkdMiu19wGQzRSuS19SingYCDITcfcS/6W8k0fR10xhh4H7Er3vUw94brQ79SD6HfqQeXGRs15iFFXjmHOJz/gcFj0P+MQLnnifESE3I6tGb3wcSY8Pokfpv5E2y65nH7DYPbut0e9ZTnlyuOZ9ubX+Iv+toIdTosOO7dj1/2612ouVWXRzKV8/d5snC4nA8/ux877dK23jIamg6rEzcIVkeOApwAH8JKqPlThfBfgFaBVyTU3q+rk6uZMKQU8//OF9uZQBYKBEJ+M+YLL/jM8CVI1Tdp0as3d799Y5fnWHbK55LHz4r5u9727cusbV/P4xc8T8AWJhMLs1ntn7pxwXa06rKgqT102mqmvfU2gOIBYwoejPuG8e85g6HWD4i63oXFib8LVP/FIRBzAs8DRwBpgrohMUtXFZS67HXhHVZ8XkT2ByUC36uZNKQVcuL0oajhSJBwhb1P9Nn8MqcMhgw/goBP3Z82v68jI8pLbsXWt51g861e+eP3r0mgNDSv+4gDj7niL/mccSptOtZ/T0BSJW0+4A4HlqroCQETeAgYDZRWwAlklf28J/FnTpCm1CbdP/56EApUt4LQMD4eefGASJDIkCofDQdc9OtVJ+QJ88/7scm6MHYglzJk8v77iGZoI9iZcTHHAuSIyr8wxosJUHYGyGU9rSsbKchdwTknZ3snAlTXJl1IKOHenHIbdckq5Xfu0DA+799mFQwYfkETJDKmGy+3EclR2WYhl4XSn1IudIcnEWJB9047WaSXH6DosNQwYp6qdgH8Ar4lItTo25f6nnnvnUPY5fE8+fnEqRXlF9D/jUPqfcUjUsKimyuZ1W/n05S9Yt2IDvY7oyRGn98WdVjlsrDkz8Ox+vPvkx4RD5a1gDUfMw9pQyo5MuDiwFuhc5udOJWNluRA4DkBVZ4lIGpALbKhq0pRTwAC9+vekV/+eyRYjKSye9Qs3H3sfoWCYoD/IV+98y5sPvMsz3z1o6jCUoeuenbnoobN58abXcTgsRIRIOMItb1xVZcq2oXkSp6abc4HdRKQ7tuI9EzirwjWrgIHAOBHZA0gDqq1klZIKuLmiqjx4ztMUF/hKx3yFftav3MibD7zHiEfOJRgIMm/KAgq2FtKr/5607dJ8O02fcuU/OHxIX+ZMno/T7aTvSX3MQ8pQDlUIRuqvgFU1JCJXAFOwQ8xeVtVFInIPME9VJwHXAS+KyDXY7ufztYYiJ0YBpxAbV29iS5Q04KA/xFfvfEtGlpfxD32AYG82hUNhTvn3P7jooXMaXtgUoXWHbI6/cGCyxTCkKLYLIj5bXSUxvZMrjN1Z5u+LgUNrM2dKbcI1d1weFxqJRD23cfVmxo18G3+RH1+Rn+ICHwFfkA+f/ZS5n/7QwJIaDI0HUwvCEBPZ7Vqx637doxbQUdWoBXR8hX4+euHzBpDOYGh81CIMLSkYBZxi3P7WNeR2yiG9hRdPugeXxxW9olkZfIW+as8bDM0XMcV4miOqdmaWO81VZbWyaLTt0oZXl4/ihy9+ZuPqTYhDeP7qcRTlRa8Kl5bhYcCwfvES22BocqRyT7gaFbCIvAycCGxQ1b1KxnKAt7HznP8ATldVU8y1hDmf/MCoK8ewfuVG3GkuTrr0WC584KyYY5kdDgd9jukF2AWKnr96XNTrXG4nu+7XnYFnH1Y6Fg6Fmfvpj6z59U+69uxM76P3qdUDwGBoSthREKmbQxCLBTwOGAW8WmbsZuALVX1IRG4u+fmm+IvX+Fg86xfuGfpYaZqsr9DPpGc/pTi/mEv/cz6+Ij8tsjNjLjzjcru4bfw13DPkMSIRJegP4nA5aNU2i0sfP5/DTj2oVLFvXb+Nqw+7na0bthP0B3F5XLTv1pYnvron6eFZvy34g68mzMIS4fChfU3VMkODEMdEjIRQowJW1Rki0q3C8GCgf8nfXwGmYxQwQEnLoMqdiye/OJUpY79EFXI75nD1CyPofXSvmOY88Pj9GPfr03zx5jds35hHn2N6sd/AvSsp8acufZH1KzeVVpQLBcKs+eVPXrzpda554V/x+YB1YNzIt5j4+P8I+oIgwsQn/sewW07h7NuHJE0mQ/MhlV0QdX03baeq60r+/hfQrqoLRWTEjgIXGzc2/fbmq3+JXgApElGCgRChYIi//tjAyFMeYcXClTHPm9uxNWfcMJgRj5zL/kftU0n5RiIRvvvo+0rlPIOBENPfmlmrz6CqLJ2zjCnjvmTxrF/q1TBz5eLVTHjsf/iLAkQiSiQcwV8c4M0H3mPNsnU1T2Aw1IMmHwVRkulR5TdUVUfvKHDRpk3Tz9rarffOiFXzP2jQF+SdRz+M27qqWqWijFQRWxyN4oJirul3BzcMvJtRV47hpmPv44qDbqFwe2Gd5Pr2w3mEg5Ur3GlEmTVpXp3mNBhqQypHQdR15fUi0gGg5M8qi000dfI25zPzgzn8+OXPhMNhzr1jCJ4YCudEIlqltVwXHA4H+x25V6WQNYfTUaviNC/e+Dq/fr8CX6HfPgp8/L5wJc9eNbZOcjldjqgPJLEEh9NsDhoSi6oQUqvGI1nUdeVJwI52CecB8TPlGhETHp/EsM7/4pHzRzHy5EcY1ukSAB6bfjf7HL4nnnQ3uR1zokY/OF1Oeh7SI67yXDP6ErJatyAtIw0Ab2YarTtmc8njsXe2mPr6DIL+8o3sg4EQ09+eGZMrYuOazUx4/H+8ds8Els5ZxmGnHVRlHHO/0w6OWS6Doa6ksgsiljC08dgbbrklhYZHAg8B74jIhcBK4PRECpmK/DxzKa+MfIeAL2g3EAWK8ou5+bj7eXPV8zw+/e7Sa5+96mU+GTOttHuDWIIn3c2Q606Kq0zturbhtRXP8tU737JqyRp26dWNw049qFalLMu2iy9LKIoboSJfTZjFI+ePQiMRQsEwbz/yIQPOPJRLnziP568ZV2IJCxqJcOWzF5muFYaEs8MHnKrEEgUxrIpTzboCykf//YxAsb/SeHFBMYtm/sI+h+9ZOnbpf86n424dePc/H1GwrZBe/Xty0UPn0LZzbkxrhUNhZn4wh3mfLSC3Yw7HDR9QZRW0tHQPx54/oG4fCuhzTC/mTJ5PJPK3tSsi9Orfs9rQuaL8Yh4dPopAmZbz/iI/09+eyRGnH8Iry0fx3f++RwT6DupDTnvTAdnQMDRqBWyITsG2QqK9kYtIpaw1y7I4+YrjOfmK42u9jr/Yz3X9R7JqyVqKC3y43E7eeXQSI9+9ngOO3beu4lfJZU8NZ8l3v+Ir8uMvCuDxunF73Vz13MXV3jd/6sKorhZfoZ8v3pjBTa9cyYn/Ojru8hoM1dHo44AN0el32sEsmL4IX2F5KzgUCLN3v/+L2zof/fcz/vh5Nf4SyzIYCEEgxINnP8WEv16Ke6eQDt3bMe7XZ/jsleks+34FO/fqyrHDB5CV06La+6rLtjOZeIZkkspxwEYB15EjzzqMj0d/zu8/rcJX6EcswZ3m4uKHzyGjZfyyzqaN/6ZU+ZYlFAzx24I/2L33LnFbaweZrTI49aoTanXPfkftTSRcOdwtLcPD0f88Il6iGQy1QhVCcSjIniiMAq4jLreLx6ffzfS3v+Wb92eTlZ3JiZccQ48Ddo3rOlVtoGlEU6pPnDcjjdvfuoZ7T38CxC4W73BYHH/hwGbbXsqQGhgXRBPF5XZx9LlHcPS5ibPwTvzXMSz/4fdyrg4Ru3Zw1z07JWzdunDQCb15Y+XzfP3ubIoLfBx4/L503bNzzTcaDAnC+IAN9eLIsw7jh2k/8eVbMxERHA4Ld5qLeyfdFHNBn4akZW6W2WwzpBRqFLChrogI14+5jDNuHMxPM5bQql1LDjhuX1xuV7JFM5Sgvs/R/MchvBocHSHzWizvcckWy1CC2YQz1JvOPTrSuUfHZIthqECk+DPYfj1Q0pUk/Adsv5EIYSxv7TYyDfFHNbV9wKm7PWioku2b8ijMK0q2GAaAgkcpVb6l+CD/sWRIY6iEEI5YNR7JwljAjYhf5v3GI+eN4s/f/gJgn8P35KZXrzBZZckkvCb6eGQtqpqSfvrmhvEBG+rNlr+2csORd1Fc8Le1tWD6Iq4bcBcvL36y9Iu+bP4Ku/OEJRxx+iHs0qtbuXmWzF7GrElzcXvdHDnsMHbapX1Dfox6oapMfW0G7z39MUXbi+g76ACG3XIKLXOzkieU1Q4iUaraWW2N8k0BGn0tCENq8MmYLyoVWw+Hwmxeu4WFMxbT64iejL1jPO8+8ZFdzUyE9578mDNvPplz7hiKqvLkpaP54vWvCRQHcDgtxj/wHleMupDjL2gcZT2eu3osn748rTQk78NnP2XGxFm8+NMTZGSlJ0eozKshfyRo2fRzL2T+OznyGMqjRC0ZkCoYBZwCbFi9CRGpVB0s4A8yZeyXfPXOt6xdvq606lpZVJX1f2zkj9zVTHziozLFcOyuzG8++D6Ww4GvyM8Xr39dWpEtFAxDMMxTl7xIOBThmH8ekVKJHRXZ9OcWJr84tdzvIBQIkbcpn8kvTmXodYOSIpeVfjIRwlDwBEQ2gZUDGVdhpTe7AoEpi4mCMERlxcKV3HfmE6z/w27VtNMu7blh7GUs/3Ely77/jXlTfmTrhu2VesyVRSPKbvt359sP50btPBH0BXntngmoatTz4VCY564ayyt3vs1TM+9LWZfEr/N+w+l2VnoI+YsDzJ/6U9IUMICVfhqkn4ZqEBETHphKaMkmXKpiFHCSKMwr4rr+IynY9nernz8WreaKg27Fk+6uVOQnGh6vm/0G7k33vbsy99Mfq2yFFKqixu8Ogv4g2zfl8dA/n+HpmffX7oM0EK13yolaa8JyWHTo3jYJElUmFuWr/llo4TiIbATPACTjXMRqlXjhmjGp7IJI3UdDE+erd2ZFVYyqWq3ydbgcpGd5ads1l7NuP42R714PQL8hB2PF0IuuKjSiLJv3W+kDYeWSNTx+4XNc2fdWnrt6LBtWJbeh6u69d6Z993aV2hi5PE4GX1n7Mp/JIFL4Grr1Egh8CaGfoXA0umkQGtmWbNGaNKpS45EsjAVcS1SVhV8t5qsJ3+J0OznqnMPrVJFs09rN+IpqtnIr4k5zc/tb13DAcfuVG+/QvR2XPTWc564ai1gWIX+QcBSLsVpEUFV++noJtxx/P0F/kEg4wvL5K5gy7kuenvUAXfdITv0JEeHhz27n3tOf4Je5v+FwWqRlpHH9mEuTJlNt0EhRSWxw2c06P0S2ooWvIS2uTJZoTRpVE4bWZFBV/jPiBb586xt7M0uEyS9O5axbT+WsW0+r1Vz/d+BueDPTyoWVxYLH6+L/DtqNNcvW0bZLLm7P36+9J1x8NH1P6sN3//ueVb/8yUf/nVLJf+xyO9n9gF1YOnsZ4dDfClpE2GXfbrTIzuTJS14o3awDe8MuHCrmhetf5YGPb62VvPEkp302/5lxL5vXbaU4v5gOu7TD4YhvPeSEEVoC4ojSP9wP/ulgFHDCMGFoTYRF3/7Cl29987eLQBV/UYA37nuXo845vMo2QdHoc2wvuvbszIqFfxAotjeWLEtKntjlv6UOpwN3movMVhnscfBunNFxRGkh9nPvHMLp1w8uvTanfTb/uPgoVJW8TXl8/e53+Iv8iGXhdDu5+OGzOea8AVzT7w7WrVhPcYGPtMw03Gkubn71SnxFftb8uq6SvKrw04zFtf2VJYTWHbKhQyNLPrFyQKvwxVuxtaYy1I1U9gEbBVwLvv1wTlS3gVjC7Mk/cNIlx8Q8l2VZPPrFSF6/dwIfPvspvgI/CqRneQmHwkQiisNpkduxNRc9dDY57Vsx9fUZfDpmGkFfkCC20n7trgm07pDDwLP7lZdJhBvGXs6xwwfw9buzSUt3c9S5R9Ctp10e8rnvH2bO5B9YPv932nbN5fChffFmpBEOhXG6HASiuC8yWiYp1rYMkUiE+VN/4rcf/6DDzm3pO6hPoyhMJM7uqHNX2xKmbDSKF8kYniyxmjyKEDFREI0DVaW4wIfH647a6sfjdeNwOColRIhll4isLQ6nxfS3vyXosy0jjdjrt8xtwZm3nEK3nl3Yd0BPLMsiGAhy3YC7yjW9BPAV+Xnj/ncrKWAoaaZ5RE96HVG5ILrD4aDvSX3oe1KfCjI5OOqcw5n6+oxyIV+edDcnX/mPWn/GeFKUX8x1A0ay9lc7JtrtdZHewstTM++nXdfY3z6ShWT/F916KYSWgThBw9DiesRzcLJFa9KksAFsoiB2MPfTH/jnLldwauvhDG75T0ZdOYaAv3zM6ZFn9cPhqqyYNRzhkMEH1HrNWZPmkbcpv5xCj4Qj+Ir85O6Uw/4D9y7tp1ac70Mj0TfVtv4V3130y54aTu+je+FOc5HRMh2Xx8WRww5j6PUnxXWd2vLqXW+zctFqigt8hENhivN9bF2/nUeHP5tUuWJFHG2xct9Fcj9Esl9C2s7Cyjg32WI1bTR+URAicpyI/CIiy0Xk5iquOV1EFovIIhF5s6Y5jQUMLJ2zjLuHPFa6YRUOhfnk5WkUbi/iplf/3hzp3KMjlz5xHs9fM862kMVWmLe/dS0tsjNrve7qpX9SXFh5E85X4GfVkrXlxjKzM8jMzoyqbHscGN82SB6vh3s+vIn1KzeybsV6uuzRMSUK/nzx+tcE/eX9qJFwhJ+/WUpxoQ9vRlqSJKsd4uwOdK/3PKpBwGlqTtREHExgEXEAzwJHA2uAuSIySVUXl7lmN+AW4FBV3SoiNQao18sCFpGrROTnEm1/dX3mSibjH3y/0qt9oDjAVxNnsX1TXrnxE/91DG+sfJ4rR13ENS9cwtt/vsjBJ/au07pd9uiIN7Oy0kjL9FRqN2RZFpc9eT6e9L/ThUWEtAwPFz10dp3Wr4l2XduQ1boFMz+Yy7eT5hIKVp/QkWgiVe2mCKm90xJn1D+DyMaj0fV7oRt6E8l/CtXKWY4GmzhZwAcCy1V1haoGgLeAwRWuuRh4VlW32uvqhpomrbMFLCJ7lSx4IBAAPhWRj1R1eV3nTBarf/kz6vfX5Xaycc3mStW2WrVpGZdOv30H9aFlbhaB4mCpG8LhdNAyN4u+g/pUur7/6YeS1TqLN+6byLoV6+nRZ1f+eddQuu/dtd6yVCQcCnP/sCeZ88l8ULBK4m6f+OoeOu3WIe7rxUL/0w/hk5e+IFgmgUUs4f8O2BVvpjcpMjU0GpiPbr2C0hrEWgCFL6NagGTdllTZUhEFIpGYFGyuiMwr8/NoVR1d5ueOwOoyP68BDqowx+4AIjITcAB3qeqn1S1aHxfEHsBsVS0qWfQr4FTgkXrMmRR6HLALa5etq5TqGgqE6LBzu3Jj4VAYsaTUN1sfnC4nT896gOeuepmZH8wB4JDBB3L50xfgdEX/p9l/4N7sP3Dveq9dE5NfnMqcT34oF0fsK/Bzz5DHGL3g8YSvH43h9w3jh2k/s2nN5tLwOU+amxvGXZ4UeZKBFoyicgH4Yih6C828GrEykiFW6qJAbBbuJlWtbPXUDiewG9Af6ATMEJG9VbXKTZr6KOCfgftFpDV2es8/gHkVLxKREcAIgC5dutRjucRx1q2n8s37c/CVSYpIS/cw+MrjS8sc/v7TSp68ZDRLZi/D6XLQ/8xDueLpC0lvUT/LK7ttS24bf0295kgEH73weblkDLCjRNYuW8f6lRuTEnWQ2SqD0QseY9b/vmf5D7/TYapEmkoAACAASURBVOd2HHF630bj+40Lod+ij4sDIhvAqr9vuakRJ+/UWqBsi+9OJWNlWYNtlAaB30XkV2yFPLeqSeusgFV1iYg8DHwGFAI/Uj7Accd1o4HRAH369ElJR13nHh156pv7GH3Dqyye9StZuS04/fpBnHTpsQBsXreVq/vdQVGenUYa9IeY/tZM1v22nv/MuDeZoieMYBUFfMSy7HrDScLpctLv1IPod2rFt79mguv/wP8XlXaWVMGRmpXskk58tM5cYDcR6Y6teM8EzqpwzQfAMGCsiORiuyRWVDdpvaIgVHUMMAZARB7AfgI0SnbepysPTbkj6rmPXvis0u570B9i2fzfWf7j7+y6b/KsjkgkwoLpi1j/x0Z23b973GQZcOahvPXQ+5XKP2blZNIxST5gA0jmv1H/d5SrKSFeSB+OSPPwg9eO+BTbUdWQiFwBTMH2776sqotE5B5gnqpOKjl3jIgsxjZGb1DVzdXNWy8FLCJtVXWDiHTB9v82yYjyFQtXRrX6HA6Ltb+uS5oC3vLXVq7rP5LNf25FVVFV9jl8T+7+4MZ6Z4cNufZEvnlvNn+uWI+vwIc7zYXlsLj1zatM2FMSEVdPyBmL5j8AwaVgZUPGxUi6iSeukji9d6vqZGByhbE7y/xdgWtLjpiobxzwuyU+4CBweXXO5sZMjwN2Zd6UBZVC1cKhMF17dq7irsTzyHmjWLdifbmiOgu/WszbD3/AOXcMrdfc3kwvz859iJnvz+HH6Yto1zWXY87rnxLxwM0dce+PtJ6YbDEaBwoaWxREUqivC6Jy/msT5ISLj2Li4/8j6A+iEftx6k5zsffhe5TWVmhoivKLWfDV4nLKF+wOEZNf+qLeChhsf+sRpx/CEacfUu+5DIbkkboK2KQix0DL3CxGzX6Qg07obVcly85g0OXHcff7NyZNpuqSIoJRescZmg8a/otI/lNEtl5OpGC0KfiuMRxJwqQix8hOu7Tn3g9vSrYYpWTltKBzj534/adV5cadLgeHnnJgkqQyJBsNLka3nA0aBALgn4EWjoHc9xHHTskWLzmkZOyVjbGAGzE3jruC9Bbe0kpsaRkecjpkc/69ZyZZMkOy0O23gRZiJ6cC+EG3o3mNLj8qPuxIxKjpSBLGAm7E7Lpfd8b9+jRTxn7J6l//pGffHgw467DmlZhgKEW1GEJLo5yJQOCrBpcnVUjlMiFGATdystu14sybT4n5+nW/r2fbhjy6792FtHRPAiUzNDwO7JfaKIV5pBk/lJtqFISh8bB9Ux53nfoov36/AqfLQTgU4YIHhnHqv09ItmiGOCHiRj1HgX8qUHYj1gPeM5IlVtKRFLaAjQ+4mXD3kMdZMnsZgeIARXnF+Iv8vHzreOZ9tiDZohniiLS8F5x7AF4gA/CA5xAk87IkS5YkYomAMFEQhkSyYdVGfpmzjHCw/Kupv8jPxMcn0eeYXkmSzBBvxMqC1hMg9DOEVoLr/xBnfAv2Ny6Su8lWE0YBNwO2bczD6XZWqusAdqEhQ9NCRMC1t30YUjoMzSjgBKGqTHvzGz54ZjJF+cX0O+1ghlx7EpmtGr5ea9c9OxGJVP5f6HQ7OeC4/RK6tpZsQZv6EYakEb2VYkpgfMAJYtS/x/DkJS+wdM5yVi1ZyzuPTuLyA2+O2gMu0Xi8Hv716Ll4ykQ9uNxOWmRnMPT6QQlZc92K9dx87L0c5z6Tf3jP4sFzniZ/a0FC1jIYqsTEATc/NqzexCcvTStXQS3oD7L5zy1MffWr0jrDDcmJ/zqGTrvvxITHJ7Fp7RYOOG5fhlx7Eq3atIz7WoV5RVx58C3kbSlAI0okHGHGxFn8/tNKXvjxsaRZw6oKwXmobxpIOuIdhDjj387JkFqkchSEUcAJYOnsZbg8zkolLP1FAeZ9tiApChhg3wF7se+AvRK+ztTXZ+AvCpQWLgK7vdNfv29g4VeL6dW/Z8JlqIiqottvAP/noMWAEy0cjWbdg5Ueexy1oRGSwgrYuCASQE6H7HLKZwcOp5WUVj4Nze8LV+Gr0M4I7Bbyq5ZW7OLSQAS+tuNjdUch8xDgh7w70UhedXcaDAnDKOAE0POQHmS3b4XlKP/rdbpdnHTpMUmSquHYZd9upGVUzrITh5W08p1a/BHY/WPLI04IzEz8+qpo4Hu08CW0+AM0EkUWQ0IQrflIFkYBJwAR4dGpd7Lrft1we914M9NomZvFHW9fQ+ceHZMtXsI56px+eDPTyj2AnG4nnXvsxF6H/V9yhBIX0evCCon2xKkG0a0XolsvQPOfQPPuQjcegQaj1W0wxBXFTkWu6UgSxgecINp2acOzcx5m/cqNFOUX02WPjjgcDgBWLV3LmFve4OdvltAyN4vTbxjMscMHNOjm1Jpf/+TbD+diOSz6nXZwXF0j3kwvo+Y8xLP/fpm5n/6Aw+ngyLP6MeLRc5O2ASfeU20ruGwvNQAi4DksoWtr0XgIzKO0nbzatZx1278hd4oJ0Us0KewDNgo4wVRUbH/+9hdXHnQLxQU+VJW8zQU8+++XWb9qI+fdVbt8/eJCH8vn/05W60y67hn7q/0b97/Lm/e/RyQcRixh7O3jufTJ4Zw44uharV8dbTvnJrVgfUXE3RvNOA8Kx2JbvRagSKtRiW9mWTyBUuVblvBfEF4FJhIjoZgoCEMp4x96H1+RvzRBAcBX5GfCo5MYet0g0lvEpgw+fPYTXrzpDZwui1AwQsdd23PfR7fQplPrau/7Y9Fqxj/wHgFf+f52z189loNP2J/cjtXf35ixWlyLeofYG3LiBc/RiNUi8QtXWQ9RSOksgaZCCitg4wNuYBZ/+wuRcOUvncPlYO2ydTHNsXDGYl686Q38RX4Kt9uFdf5YtJrbT3ywxntnTJxFMFC5nZGI8O2H82JavzEjzi5I+tmI99SGUb4A3lOAKOUgrRxwdEMjW4jkP0pk4/FENp+F+j5vGLmaCylcjMco4Aam464diObyCwVC5NZgve7gvSc/wl8hzCsSjvDn8r/4Y9Hq6m+uwhpLYSOh0SMZ54BrT5D0khEvSAaS/RRoHrrpZCgcB+Hf7ESRbdcTKXgmmSI3GWKJgDBREM2IM28+GbfXXW7Mneai70l9yG4bW1ba1vXbo447XA62b6o+prXfkL643FE8T6ocMrhPTOsbaoeIB8l5E2n1NGRchmTdhLSZjrj2QYvegMhWytfvLQbTTDN+pHAUhFHADcyefXtwy+tX0XqnbFweJy6PiwHDDuOGcZfHPMfBJ/bG7XVVGg8FQuzee+dq7+2+VxeG3XIK7jQ3TpcDl9uJO83FpU8Ob9L+32QjYiGew7FaXI2kn4VYJQ9b/9dA5aQVxAXBRQ0qY1MllS3gem3Cicg1wEXYb7A/AcNVteGrzTQyDj35QA4ZfADbNuaR3iINj7d2rYEGXXYsk1/6gi3rtpaWmPSke7jowbPwZta8iXf27UM4fGhfvv1wXkkY2kG079a2Tp/FUE8cHSAoVHICaRgs828SF1LYv1ZnBSwiHYF/A3uqarGIvAOcCYyLk2xNGhGJ2eVQkYyWGfx3/iN8+NwUZk2aR3a7lpx61Qm1qvPQuUdHzrix6SeFpDqScT7qm0r5MDUnOHdGXLslS6ymQ5It3JqobxiaE/CKSBBIB/6sv0iGWMhomcFZt5zKWbecmmxRDPVAXPugWfdB/t1AxE7ScPVEWo1KtmhNh6aogFV1rYg8BqzCTi/6TFU/q3idiIwARgB06dKlrssZDE0WK30Q6j0OQr+B1RJx7JRskZoUksKh1vVxQWQDg4HuwDZggoico6qvl71OVUcDowH69OmTws8iQ1lUlflTF/LJS1/gK/Jz5Fn9OGJoXxxOR7JFa5KIuMG1R4Ospargn44WTwANIt5BkHY8IiYvq6Gpz2/8KOB3Vd0IICLvAYcAr1d7l6FR8NLNrzPpuSn4Cu0d+gXTF/H5q9O5/+NbsSwTPNOY0fz7oGgiO+piaGAOFE+C7BcQaYL/tils9tXnt70KOFhE0sWuJjIQWBIfsQzJZN3v6/ngmU9KlS+Ar9DPz98sZe6nPyZRMkN90dDvUPQO5YsSFUNwLgRmJUusxNFUEzFUdTYwEZiPHYJmUeJqMDRufpz2c1Qr11fo57uPvk+CRIa4EfiWqGU5tQj1T29oaRqGFE5FrpfTR1VHAiPjJIshRUjPSkcclRWw0+UgKyczCRIZ4oa0BHFEUTousFolQ6LEk8IuCON1N5Sydvk6Xr5tPAumL8IXpXuzw+ng6PP6N7xghvjhORK4M8oJB+I9uaGlSThCakdBNEGPu6EubFi1kUv3v5GvJ37H9o15pT3tnG4n6VlePOkerhtzGZ1265BkSZOH3VZoAVr0nv1nlWUmUxex0pHsl0CyQTJAMu0iQS0fRxxNMDEnjj5gETlORH4RkeUicnM1150mIioiNRZXMRZwM0VVWTRzKQumLyajVTrvPDqJ4oLoWeTXv3wZfY7dF29GlJKKzQSNFKBbL4DgLyBiV5Vz9YDslxErPm4Z1SD4v4LwGrt6muuAhHTLEPf+0HYmBOeDBsHdG5Em/G8bh+ekiDiAZ4GjgTXAXBGZpKqLK1zXArgKmB3LvEYBN0PC4TB3n/YYP3zxE/6iAJZDCIeiv6e501zkdmzdJJSvhv+0ayw4OtVasWn+QxBcDAT+/kIHF6P5DyIt74+DbOvQzWeC5tlKUZzg3B1yXklIxw4RJ7gPjPu8KUl8XlQOBJar6goAEXkLOw9icYXr7gUeBm6IZVLjgmiGTHvjG3744id8hXZnjqqUL0DQH6JN58ZdJU1DvxHZeAK68Vh00wnopqPR4E+1m6R4EhCoMBiA4v/FR8ZtV0JkHWihPa8W2Qq+IPEpyapBVCt+tqZDjC6IXBGZV+YYUWGajkDZYttrSsb+Xkdkf6Czqn4cq2zGAm6GfDp2WrkY3+rY+/A9yN0pJ8ESJQ5VP7r5LNBtlJpC4VXoln9Cmy+RmHf+g7Ucj51IaDUEF0Y5E4DiD6BFTMZUrdHwRjTvDtvtgaLuA5Gs+xFn7P0FGwWxWcCbVLXOBbHFzmB5Aji/NvcZC7gZEuvrtzczjZHvXp9gaRKMbyq25Rql3GPxR7HP4+5L5a+LVTIOGskraSs0kMimE4kUjkc1xu33oolVn4skprqragjdckaJ8g0DEQjMQTcPRSNFCVkzKagdBVHTEQNrgbJPpk4lYztoAewFTBeRP4CDgUk1bcQZBdwMOXb4ANIyqq5B7PI4Scvw8PDnd5IeQ33hlCayAaK+XvvQcGw9+AAk6y6QFvzd2y0NpAWSNRLVYnTzaSVthVZD6FfIfwjdflNsk4eXV33OtU/MMtYK/1clnTjCZQYjoD7wTU7MmskiPokYc4HdRKS7iLixS+9OKl1Cdbuq5qpqN1XtBnwHDFLVahstGhdEM+TIsw5j5gdzmDdlAUF/EHea3V3j5CuPZ8tf2+i4a3uOu+BIctpnJ1nS2NHQSjTv7pJ0Wjd4T0Ja3AKufe0NLa3gKpB0OxogRsTZBdpMRYvehdBicO6BpJ+GWK2IFL4D4Q1Uaivk+xQNXY44u1U/uatniSVa8UEh0CL2Tim1IryyigdTERpaES1XrtESj1RjVQ2JyBXAFMABvKyqi0TkHmCeqk6qfoboGAXcDHE4HIyceD1LZi9jwZeLaJnbgsOH9iWzVUayRasTGtmGbh4Cmo/d5r0Yij9AQ8sgezy4ekNgHn8XPfeAY2fw9K/VOmK1RDIvqHwiOIvytRV23OCA4AKoQQGL9wy08OWSh8QObeEE1/5Y7gT16XPubrc9ivZgaqCqbA1GnMK1VXUyMLnCWLSsFlS1fyxzGgXcTBER9jx4d/Y8ePdki1JvtGgiqB9b+e4gAKGlSHgRZP8XLXwdiifY13gHIxnDsUM744CjM+Ci8oacgNWuxtvF0Rpav4Pm3QOB2SAeSDsZyYrRhVEX3IeAowuEVvC35e0EKwfSjk3cug1Nkms91ITxARsaP6FFlG/pswOB0HJE3FiZF2C1+QSrzRSszMviGlsr6WdQ2ZaxbGUWY6ytOHfGyhmH1X4J0nYWSBq6oT+R9fsT2XYDGt4YN3mhpElozhvgHWL7tiUD0k5CcibYtYmbCEJqV0MzFrCh8ePcE/iCSkpYFZy7JHx5cXSE7NHo9ushsh2IgGsPpNXTta6vq6rolgsh+BOl3ZJ9H6GB7yB3CmKlx09uqwXS8i5oeVfc5kxFmnJPOIMh6Uj6ULRwdIkbYse3zQ3O7qhvNhqYD2mnYTlaJE4Gz0HQZoYdBSFpiKOOHY2DC0va0ZeN0w5DJB8t/gjJOD0e4jYYqgqRPwEn4qjZHZMYIZKzbCwYF4Sh0SNWK6T1RNuviQNIA0dXCC2Bwkch/wHY2IdIwZjEyiGCOLvUXfmCLXNUjVEEoQV1nzcJaHAhuukYdONx6MajiGw6GQ2tTIIgMRxJwihgQ5NAnF2xcsZitV8C2WNKYmvLfrMUCh4mEqom5jYVcHS1oycqkQaOXes1tYZWosFfUA3XfHE90cgWdMt5drgbfvsILUW3DGvYtOem2hHDYEhZCkdTpVmT/2RCl9bwZiLbbyGyvg+R9QcTyXsY1SghajuuVx/qn4H6v0bVD+6DSiInynoHBcSNpJ9SN5lCK+1aGJtOQrecgW48FPXPrNNcMa9Z9KGdbViOCGgxNHTnjRS2gI0P2ND00IKqz4XXJ25Z9aFbhpSsEbIHi15Dgz9AzvhKKeDq+xLdfg2ldpAqtHwAcl6FvJGlNRpw7Y20fKAWdSvKyhRCt5wNkY32XIrdfmjrZdBmcuJqAEf+JGpkigYh/Fdi1qwCU5DdYGhI0qqxFBMZ4+qbXJLeGyozGIDgfHTj4UQK3yot4q7hjei2q+yqZ1pQ8tAohO1XwaZjwLU3tP0BafcDVut3EGcd3Q+Bb0sqrFU080Jo0YS6zRkD4u5tF3qvhAPc+yZs3aiyGBeEwdBwSPoQsKJYdtIKSR+WsHU1sNBWqNGIrIf8B9H8x+2ffZOp8t1Xi6DwBSh6rVyhdNUg6puCFoxCiyfH5ksNb6pinSCE/6z5/rriGViSoFK25kgauA9AElXfIhqxuB+MAjYY4oeIBblTwXseSCu77U7aqUibTxErMenWqhEIzK3hqmIoegWN7LB4qyllqcVQ+MLfFnNkC7rpOHT7zWjBM2jebejGo9HwhuqXdO8fxReLnXLsObQGeeuOiAvJeQsyLrIVsWNnyLwKyX4+YWtWSQorYOMDNjRJLMsBLW+zj1qgod8g8J3dPThtYOwZc4Gv7VZCNSEuOzLAfRjIaFvRVilMPraSdqN590F4HaXuDS0E9aF5dyHZz1W9nLMb6j3RtrhL1/LYSjHt+Ng+Wx0RKwNpcRW0uCqh61QrAyYRw2BIeVQVzRsJxe/bA+KEvDshZ1xMr8zqm0rUgjyVLgyA1d5OU/YcA/7Pq3ZbWO2wa0wAvs8p71sGCIN/OqpabY1nybof3AegReNtJZz2DyT9vCaVclwdEkldDVxnBSwiPYC3ywztDNypqomN8zE0aVQDaMELUPy2ndnmORJpcV39khtiwf85+D6kNANN7T9167+gzTc1F+6RTOwkkOpibD2QdpRdfAeg5SPgn4YWjrEbZJYrJpQGLW6KS1NOEQu8pyLeU+s9V21R9UHxZDT4PTi6Id5T//78DSIAKZ0JV2cFrKq/APtCacfQtcD7cZLL0EzRbZeDfzalIUy+/6GBmZD7aVy6D2ukEC14qqTHWxjSjkNaXIsWvRPdHaA+Oz3YvV+180r6aWjRG1RWwIKtmB3gPQXJ+tslIiK2myNtIOqfjRY8BqHfwNEZybwaSRvw9zRpx4DvE8pbwU7wDEhI5+R4oJGtdpnQyOYSK9+DFj4HOa8jrp4NJkdzcEEMBH5T1STkGRqaChr8pbzyBSBUUgfhAyTjnPrNr2r3ggv9QmkJxuJ37UI30r6Ku4RY+r6Jc1c06w7Iu8f286KABa3+i7h2B/FW+8ovnoMQT9VhYZJ1GxpcUKLMikG8IC2RrJE1ypYsNP+ZkpjfHb8/P6gf3XYD0qYBu240AwV8JjA+2omS7qIjALp06RKn5QxNktASECvKF6YYAvOhngqYwHcQ/o3ynSdCdpJC2iEQWkhUP64rtrhVK30omnas3ZVD0sDdN25+VrFyIPcT8H8JoeXg3Nl2z6SyH9c/hagPr/BKNLLF/kwNQJO2gEv6Iw0Cbol2XlVHA6MB+vTpk8K/CkPScXSq+pz/KzT4M+Laq+7zh5ZQqQME2K/H4rXdDMEfS16XXYADafl4rZScWFkJS/YQcdmuCI5JyPzxx1XNuQbc/09hrROP38LxwHxVTVyOp6F54OoNjo4Q+p3KO/75Ja3kZ9TdF+zoAuKOooTTEWd3aHEjBL5G/V+D1Rrxnow4OtRtLQOkD4WCFyjvUnKAa3/7QdUQaNNPRR5GFe4Hg6EsqhE0tAoNb4p6XkSQnNeqLqKukZKNqDri6W/H95b7b28XuiHtBLtLhOcIrKzbsTIvNcq3nkjGxSUdQbzYXaQzwLET0urRhpOB1E5FrpcFLCIZwNHAv+IjjqGpov6v0e03Q6QACKOuXkirJxFHm3LXiZUDacejBb9S+d3RV1JUpm6IOKH1W+j2W+zea1BS6OahuERYGMoj4kZyXkKDi+wOH45O4D6k1l1C6o2mrg+iXgpYVQuBBgzqMzRGNLQC3Xo55V5Fg/PRredD648qh1G5ets+2YoJCpJmn6sH4miP5Iy141M1EtcWP/VBNQC+Kah/Gli5SPoZpQV4VEPg+wT1fWRHU3iHJjSNON6Iqyc0YNhZpfVTV/+aTDhD4tHCN6i8Gx6G8FoI/QQVM83cB4KrFwR+4G+lnWaPxdjksiZE0uz30xRA1W+XjAwuB4oAB1r0NtryASTtH+jWERD4nh0RGur7Ek3/J1bWdckUu3HQVBMxDIaYCa8meoaY2LVzK2yWiwhkv2inzha/aw96T0PSh6Vs0kF90KJ3Ifgrfz9swvaRdzuKqyRLrmx4XDEUjUMzhiGOnRpc3sZGKm/CGQVsSDzug+0Y3Epdi4N23dsoiLiRjPMg47zEy5dsfB8TtXg5FhS/F71WhDjA/y2kD0m0dI2eVFbAphylIeFI+ulgtaKcqSteuz6Bo6oMtGaEVLUBGCn5vUWzkwSsxHV5bjIo9iZcTUeSMArYkHDEykRyP4D0s8HqBM7/Q1rcgWTdnWzRUgLJGGY/kCqdaAUZ/yK6ArbssDpDjaRyGJpRwIYGQawcrKxbsdpOw8qdhKQPaZL+3DrhPgK85wJuIMOOl7VykewXsVw7Q9Z92HG0mfY5aYVkv4yIp4aJDYApyG4wGKpGRJCs69GMc+yuGlarkjoS9tfTSh+Epg2E4DzAA+4+pecM1WMKshsMKYwGf0WLxkJoJbgPQjLObbAiMRURR3vwnhT9nJUBniMaWKImgGrTLMhuMDR21D8D3XoFdnW0CAQXokVvQu6HZnOwKZG6+tf4gA3NE1VFt9+GHf61I04pAJqHFjydRMkM8SaVN+GMBWxonkTWQ2RblBNh8H/V4OIYEoQCxgVhMKQYkkH5Hmxlz7VsUFEMCSZ19a9xQRiaJ2K1AE8/KudBeyH9/GSIZEgQ8XJBiMhxIvKLiCwXkZujnL9WRBaLyEIR+UJEutY0p1HAhmaLtHy4pBBQGkgLwA3eIUj60ISuq4E5RDafQWT9/kQ2DUJ9XyR0veaORLTGo8Y57MbDz2I3oNgTGCYie1a47Aegj6ruA0wEHqlpXuOCMDRbxGqJtB6Phn6zm0c6eyCO3ISuqf7Z6NaLKa39EFqKbrsGzboPK31QQtdulsQv0eJAYLmqrgAQkbeAwcDi0qVUvyxz/XdAjU0MjQVsaPKofxaRzUOJrO9NZNNpqP+bcufFuQviOTThyhdA8x+mcuEdHxQ8gqZw4fDGip2IoTUeQK6IzCtzjKgwVUdgdZmf15SMVcWFQI3tW4wFbGjSqP/r8sXgQz+hWy9DWz6O5T264QUKLY8+HtmMLWOUmhCG+hFbNbRNqtonHsuJyDlAH6DGzBljARuaNJr3INEtzoeTIQ5UleAh6YCp7ZAIYrSAa2It0LnMz51KxsqvJXIUcBswSFX9NU1qFLChaRP+vYrxVagmoVBsxpVUtnK9kHFxw/dKaw7EUognNs/PXGA3EekuIm7gTGBS2QtEZD/gBWzluyGWSY0LwtC0sXLtpIuKSE5SFJ6VfhIRzYeCJ0EL7Y7MGRchGXZfW1W1O4iIA3FU52I0xEZ8akGoakhErgCmAA7gZVVdJCL3APNUdRLwKJAJTCip9LdKVavdWTUK2NC0ybgc8h+kfEsfL2RekiyJsDLOQtPPBM0DySytbKaBBej2ayC8CVDU0QXJfhpx7pI0WZsEcdrcVNXJwOQKY3eW+ftRtZ3TvPMYmjSSfga0uOrvOF/JhMzLkPT4tTpSDRIpeJbIhn5E1vchsu16NPxX9XKJhVit/la+ka12l+jwGmyftR/Cy9HNZ9sdkw11Q+2WRDUdycJYwIYmjYggGReg6f8ssTiz4l5LV7ddA/4ZlG72+T5GAzMh91PEii2tWYsngVZsXKqAH/zTIO24eIrcvEjh8L56WcAi0kpEJorIUhFZIiJ94yWYwRBPRJx2nd/IRiLbrrGz0DYcQiT/yXpZmBpaUVK8p2ykRRgihWjRxNgnCq8jamNODdqdoxOEhlYS2X4rkU0nEtl6FRpcXPNNjY0m3BHjKeBTVR1SsjOYHgeZDIaEoJHt6KZTQLcBEdACKHwZDS1Bsl+o26TBpdhfo4oRR76SdvIXxjSNuHujxW9F6YDsANe+la5XVQh8h/omAy7EOxhx96qV6Br8Bd1yBqgfCENoOer/ErKfRzyH1mquVEYiqdsWuc4WsIi0BA4HxgCoakBVo9X3MxhSAi2aUKLgyn4hw1zFRAAAC0BJREFUfeCfhVaVIFETzk5Ej/R3Q202zzwDwNGd8rHAaeA+oKRexd+oKpp3K7rtEih+G4rfRLecS6RgVK1E1/yHSn4fO1wfEcCH5t1Vq3lSGsX+WDUdSaI+LojuwEZgrIj8ICIviUhGxYtEZMSO9L6NGzfWYzmDoZ4EfyDqa744IPhL3eZ07g3OnalcVc2JpA+LeRoRJ9L6Tci81FbEjt2gxbVI9vOVm5cGf4DiyaA7IjtsxUnBC0QKXyWy8Vgif/UisnkIGphT9aLB+dHHw2vQSGHMsqcyQs1JGDEmYiSE+ihgJ7A/8Lyq7gcUApVKtKnqaFXto6p92rRpU4/lDIZ64twNu/NwBVTB2bnyeAyICJIztqRFvAtwgnN3JPsVxNGhlnN5sTIvw2ozBavNx1gZ5yPiqnSd+qYS9UFCGPIfLkk+KbZbLG25CA3MrWLBVlVI4oKm1HFZteYjSdRHAa8B1qjq7JKfJ2IrZIMhJZH0M6GSQnPZFqxz77rPa7XCyn4Wafc90vY7rNyPau2Prd2CXuxcgIqEgGCFMR+a/3j0eTKGUzkrLw28pzWtrstNUQGr6l/AahHpUTI0kDKl2QyGVEMc7ZGc18G5J7YCc4FnIJIztvJrfl3mlzTEyqr3PDWu4z2J6Aq4CkLLos+T/k9IP4PS+Gg8kDYQybolHmKmBinuA67vY+5K4I2SCIgVwPD6i2QwJA5x9URyP7B9nOLC/q/buBBnNzTrTsi7B3DaNRd1hyaJUv+lipRmEQvJuhXNvBxCf4CjY4OU5GxoUjkKol4KWFV/xC67ZjA0KsSqtF/cqLDSh6JpR4H/a8AJnsPRorFQ8BLl067TkMyrqp1LrJaQSJdJUkmui6EmmpCjx2BoXoiVDd4ytV4yLkdxQOFLdoSElQOZNyFpA5MnZLJRjAI2GAw2GtkOvs9A88F9KOLqUfNNMSJiIZmXoRmXgPpAvHHxbTd6UtcDYRSwwZBoNDAfLZ4AodUQ/BF77zsMPIl6B/1/e3cfI1dZxXH8+5udzu52t7TdYhukSgnUl8ZEMdhWwEasShvRGkOMGCMxKCEGJBJjaGxCfEs0kVBDkLjWYoOkxRQMDQgFi4oNWihWkwJVmyqlpbC1XZZt933m+MdzW7bT3ZndnZ155uV8kpuZnblz78lt9uz0uc85Dzrn+9OaKKVU0uDdAVHn+RbjCdi5Msqd+Dmc+Blh3m5+IhiGgUegeSW0XBkhugbhCdi5xmPZLjhxF1Cg2Y/1Yf0Phptg2WOQficqsQjChv6O9T8AuR7UsgpaVo9Z0NEQzCBbvWMQnoCdK5ehvxB+xYp0Wxveg3WtSIpEDGu/lVTbl6d0ytzJe6H3TsJ0NMMGn4G+LdCxqbGTcJXyhuzOlYvaoOjYbgpy3cBQWKLI+qD3Dmxgx6RPZ7lu6L2DM4c7+mD4RRjYPunj1Y16rIRzrlrY0HPkjn81NKHp+Q428krskILmj1D4V6wleRzJe70fOzmF9phDz4Y15s7Shw08Pvnj1QMDclZ8i8SHIFxNy/U/Cj1rOd2cpv8gNvAYzHsIpRfFDC2M5c7dgHV/jdMtH204tJ5MXwTpi+HNdWP0AGZqTdjVPs4bKZjgyhz1x5IqwerkCdjVLLNsUo6btxqF9WG969Hc9bFCO02ZS2D+MzD011AckVl+epkis2HszdvH+FQKMssnf7LMMsbs9kYmrI03RWb9SanygrCqSC0xqvomnA9BuNqV6xrVE/eMN2C4QB/cCpMyqHkFarnqjDXipBkway1vDUUANIHaUPtNUzhPGnVsBHUk489Jg51Z30J5Td0nKneiE3t9OXb8i1jXCnLdN4eEXEuqeAzYvwG72qVZjFvmlKqNpjKpmddgTeeFMd/sq5BZhtpuRFPtTzxjCczfGcaD7SRklk54YdB81v87OHE30P/WPb3BP2I969CccVpcVqMqngXhCdjVLKXasZarQmnvGV3AWlHbDbHCmjQ1Xz6ta7BJaWi+rOTj2MlOzmzsAzAIA9ux3HdRarwx52rizXicKxvN/kFY1XjwD2EereWg/UbUenXBz1n2CNb3IOS6QvJrXllfTcinQ268JcRSYG8CNZCADajXdpTOxSa1orl3YdljYUy46QKUKtwHwQZ3Yt1fJwxfDGED28KMhI77S65CqyuZpTDwGGcN86gVUguihDQlVfwN2G/CubqgpnloxnuLJ18bwd64lTBzIqlQsz4Y/hfWt7nscdYStd+SNPUZvfpGK5yzDmkSK3JElZQiF9si8QTsGsvIPs5eNw1gAPq3VTqaqqb0IjTvYWj9HDQtgswVqOMXpFo/HTu0iTMwyxXdYvEhCNdgMow7c8KHH86i9DvQ7B/GDqM0ESvdivFvwK6xpBePPUVNrWjmtZWPx5VfFc8D9gTsGookNOce0NxQrEALYTXg1dBSeOaEq0FmYRZEsS0SH4JwDUcz3gXz/wyDf4LcMch8CKUvih2WK5cqngXhCdg1JCkDLZ+IHYYrO8Oy2dhBjMsTsHOufp1qR1mlSkrAkv4L9BJ67Y2Y2aXTEZRzzk2bKm5HOR034a40sw948nXOVRsDLGdFt4mQtErSPyXtl3TbGO83S3ogeX+XpEXFjumzIJxz9cuShuzFtiIUSv/uBlYDS4BrJS3J2+16oNvMLgbuBH5c7LilJmADnpD0vKQx209JukHSbkm7jx4dr7mHc86Vh2WzRbcJWArsN7MDZjYEbAHW5O2zBtiUPN8KrJQKLwpY6k24K8zssKT5wJOS9pnZ06N3MLNOoBNA0lFJL5d4znpwLvC/2EFUAb8OgV+HIP86XFDqAXvp3v572zqR5tAtknaP+rkzyV2nnA+MXmzwELAs7xin9zGzEUk9wDwK/NuWlIDN7HDy2CXpt4S/Ek8X2P9tpZyvXkja7WPmfh1O8esQlOM6mNmq6TzedJvyEISkNkmzTj0HPgnsna7AnHOuihwGRi9TsjB5bcx9FJpLzwaOFTpoKWPAC4Cdkv4BPAs8amYNuva1c67OPQcslnShpAzwBSC/fd424Lrk+TXAU2aFy/CmPARhZgeA90/18w2us/guDcGvQ+DXIaja65CM6d4EbCc0SN5oZi9I+h6w28y2Ab8E7pO0HzhOSNIFqUiCds45VyY+D9g55yLxBOycc5F4Aq4wSU2S9kh6JHYssUiaI2mrpH2SXpL04dgxxSLpm5JekLRX0mZJLbFjqgRJGyV1Sdo76rUOSU9K+nfyODdmjJXgCbjybgFeih1EZD8FHjez9xBu5Dbk9ZB0PvAN4FIzex/h5k7RGzd14ldA/hzd24AdZrYY2JH8XNc8AVeQpIXAp4ANsWOJRdJsYAXhjjFmNmRmb8SNKqo00JrMG50JvBo5nopIKmaP5708upR3E/DZigYVgSfgyloPfJtxV4VsCBcCR4F7k6GYDUkhT8NJKkl/AhwEjgA9ZvZE3KiiWmBmR5LnrxFqDeqaJ+AKkXQ10GVmz8eOJbI08EHgHjO7BDhJA/xXcyzJGOcawh+ltwNtkr4UN6rqkBQw1P0cWU/AlXM58Jmkif0W4GOSfh03pCgOAYfMbFfy81ZCQm5EHwf+Y2ZHzWwYeAi4LHJMMb0u6TyA5LErcjxl5wm4QsxsrZktNLNFhBstT5lZw33bMbPXgFckvTt5aSXwYsSQYjoILJc0M2lbuJIGvSGZGF3Kex3wcMRYKsLXhHMx3Azcn9TUHwC+EjmeKMxsl6StwN+AEWAPVVyOO50kbQY+Cpwr6RBwO/Aj4DeSrgdeBj4fL8LK8FJk55yLxIcgnHMuEk/AzjkXiSdg55yLxBOwc85F4gnYOeci8QTsnHOReAJ2zrlI/g+AVPkAmFLwQwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(X[:,0],X[:,1],c=y)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjhq9yb1OLPJ"
      },
      "source": [
        "## Perceptron in PyTorch\n",
        "* [PyTorch NN Module docu](https://pytorch.org/docs/stable/nn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chTPD5_3OLPK"
      },
      "source": [
        "### define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2y4cGUHEOLPL"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "\n",
        "class Perceptron(torch.nn.Module): #all nets inherit from nn.Module\n",
        "    def __init__(self): #define layer types\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.fc = torch.nn.Linear(2,1,bias=False) # Perceptron is single neuron \"fully connected\" (fc) -> linear unit with 2 inputs and 1 output \n",
        "        self.non_linear = torch.nn.Sigmoid() #non-linear activation \n",
        "\n",
        "    def forward(self, x): #build network\n",
        "        output = self.fc(x) #w*X\n",
        "        output = self.non_linear(output) # activation \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJNli7kwOLPN"
      },
      "source": [
        "### prepare training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lblPnCgxOLPP"
      },
      "outputs": [],
      "source": [
        "#make blob data\n",
        "x, y = make_blobs(n_samples=100, centers=2, n_features=2,center_box=(2,10),random_state=42)\n",
        "\n",
        "#split in train and test \n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#np->torch\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#have look\n",
        "y_train"
      ],
      "metadata": {
        "id": "7CoeAvQEQDYF",
        "outputId": "bff773dd-4047-457f-86dc-fdace0ecdbec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
              "        1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
              "        0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SJcBxFnOLPQ"
      },
      "source": [
        "### get instance of model\n",
        "and set optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gBYRw8CEOLPR"
      },
      "outputs": [],
      "source": [
        "#get instance of perceptron model\n",
        "model = Perceptron()\n",
        "\n",
        "#define loss function\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "#define optimizer -> SGD with learning rate lr\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)    # 0.01"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run test data theogh untrained model\n",
        "model.eval() #set to eval mode\n",
        "model(x_test)"
      ],
      "metadata": {
        "id": "OqhuuS00S_Qf",
        "outputId": "f6ad8256-a9f1-4534-96f2-49a4ecb79af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9718],\n",
              "        [0.7422],\n",
              "        [0.9931],\n",
              "        [0.9535],\n",
              "        [0.6142],\n",
              "        [0.9343],\n",
              "        [0.4698],\n",
              "        [0.5598],\n",
              "        [0.9559],\n",
              "        [0.9845],\n",
              "        [0.5162],\n",
              "        [0.9821],\n",
              "        [0.6939],\n",
              "        [0.9616],\n",
              "        [0.3245],\n",
              "        [0.8339],\n",
              "        [0.6155],\n",
              "        [0.9915],\n",
              "        [0.9904],\n",
              "        [0.9861],\n",
              "        [0.4977],\n",
              "        [0.5228],\n",
              "        [0.7528],\n",
              "        [0.8615],\n",
              "        [0.7241],\n",
              "        [0.7315],\n",
              "        [0.9786],\n",
              "        [0.9791],\n",
              "        [0.9858],\n",
              "        [0.5738],\n",
              "        [0.6342],\n",
              "        [0.9835],\n",
              "        [0.9803]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZYHV-FDOLPR"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "18hUejMbOLPS",
        "outputId": "e4515079-7243-4faa-e29a-9ca6083bd314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 2.265535354614258\n",
            "Epoch 1: train loss: 2.1020779609680176\n",
            "Epoch 2: train loss: 1.9670295715332031\n",
            "Epoch 3: train loss: 1.8577810525894165\n",
            "Epoch 4: train loss: 1.770310401916504\n",
            "Epoch 5: train loss: 1.7002230882644653\n",
            "Epoch 6: train loss: 1.6434718370437622\n",
            "Epoch 7: train loss: 1.5966793298721313\n",
            "Epoch 8: train loss: 1.5571906566619873\n",
            "Epoch 9: train loss: 1.522993564605713\n",
            "Epoch 10: train loss: 1.49260675907135\n",
            "Epoch 11: train loss: 1.4649580717086792\n",
            "Epoch 12: train loss: 1.4392822980880737\n",
            "Epoch 13: train loss: 1.4150421619415283\n",
            "Epoch 14: train loss: 1.391863465309143\n",
            "Epoch 15: train loss: 1.3694918155670166\n",
            "Epoch 16: train loss: 1.3477522134780884\n",
            "Epoch 17: train loss: 1.3265291452407837\n",
            "Epoch 18: train loss: 1.3057444095611572\n",
            "Epoch 19: train loss: 1.28534734249115\n",
            "Epoch 20: train loss: 1.2653053998947144\n",
            "Epoch 21: train loss: 1.245597243309021\n",
            "Epoch 22: train loss: 1.2262095212936401\n",
            "Epoch 23: train loss: 1.2071341276168823\n",
            "Epoch 24: train loss: 1.1883656978607178\n",
            "Epoch 25: train loss: 1.1699014902114868\n",
            "Epoch 26: train loss: 1.1517393589019775\n",
            "Epoch 27: train loss: 1.1338773965835571\n",
            "Epoch 28: train loss: 1.1163156032562256\n",
            "Epoch 29: train loss: 1.0990525484085083\n",
            "Epoch 30: train loss: 1.082087755203247\n",
            "Epoch 31: train loss: 1.065419316291809\n",
            "Epoch 32: train loss: 1.0490469932556152\n",
            "Epoch 33: train loss: 1.0329692363739014\n",
            "Epoch 34: train loss: 1.0171846151351929\n",
            "Epoch 35: train loss: 1.001691222190857\n",
            "Epoch 36: train loss: 0.9864873290061951\n",
            "Epoch 37: train loss: 0.9715707302093506\n",
            "Epoch 38: train loss: 0.9569393396377563\n",
            "Epoch 39: train loss: 0.9425904750823975\n",
            "Epoch 40: train loss: 0.9285217523574829\n",
            "Epoch 41: train loss: 0.9147299528121948\n",
            "Epoch 42: train loss: 0.9012125134468079\n",
            "Epoch 43: train loss: 0.8879660367965698\n",
            "Epoch 44: train loss: 0.8749874234199524\n",
            "Epoch 45: train loss: 0.8622726798057556\n",
            "Epoch 46: train loss: 0.8498188853263855\n",
            "Epoch 47: train loss: 0.8376222252845764\n",
            "Epoch 48: train loss: 0.825678825378418\n",
            "Epoch 49: train loss: 0.8139849305152893\n",
            "Epoch 50: train loss: 0.8025363683700562\n",
            "Epoch 51: train loss: 0.7913290858268738\n",
            "Epoch 52: train loss: 0.7803593277931213\n",
            "Epoch 53: train loss: 0.7696229219436646\n",
            "Epoch 54: train loss: 0.7591152191162109\n",
            "Epoch 55: train loss: 0.7488325834274292\n",
            "Epoch 56: train loss: 0.7387701272964478\n",
            "Epoch 57: train loss: 0.7289237976074219\n",
            "Epoch 58: train loss: 0.7192897796630859\n",
            "Epoch 59: train loss: 0.7098631262779236\n",
            "Epoch 60: train loss: 0.7006399631500244\n",
            "Epoch 61: train loss: 0.6916157007217407\n",
            "Epoch 62: train loss: 0.6827865839004517\n",
            "Epoch 63: train loss: 0.67414790391922\n",
            "Epoch 64: train loss: 0.6656953692436218\n",
            "Epoch 65: train loss: 0.657425582408905\n",
            "Epoch 66: train loss: 0.6493334174156189\n",
            "Epoch 67: train loss: 0.641415536403656\n",
            "Epoch 68: train loss: 0.6336678862571716\n",
            "Epoch 69: train loss: 0.6260858178138733\n",
            "Epoch 70: train loss: 0.6186662316322327\n",
            "Epoch 71: train loss: 0.6114048957824707\n",
            "Epoch 72: train loss: 0.6042980551719666\n",
            "Epoch 73: train loss: 0.5973419547080994\n",
            "Epoch 74: train loss: 0.5905329585075378\n",
            "Epoch 75: train loss: 0.583867609500885\n",
            "Epoch 76: train loss: 0.5773422718048096\n",
            "Epoch 77: train loss: 0.5709532499313354\n",
            "Epoch 78: train loss: 0.5646975040435791\n",
            "Epoch 79: train loss: 0.5585716366767883\n",
            "Epoch 80: train loss: 0.5525722503662109\n",
            "Epoch 81: train loss: 0.5466964244842529\n",
            "Epoch 82: train loss: 0.5409411191940308\n",
            "Epoch 83: train loss: 0.5353029370307922\n",
            "Epoch 84: train loss: 0.529779314994812\n",
            "Epoch 85: train loss: 0.524367094039917\n",
            "Epoch 86: train loss: 0.5190635919570923\n",
            "Epoch 87: train loss: 0.5138659477233887\n",
            "Epoch 88: train loss: 0.5087718367576599\n",
            "Epoch 89: train loss: 0.5037781000137329\n",
            "Epoch 90: train loss: 0.4988826811313629\n",
            "Epoch 91: train loss: 0.49408283829689026\n",
            "Epoch 92: train loss: 0.48937636613845825\n",
            "Epoch 93: train loss: 0.48476091027259827\n",
            "Epoch 94: train loss: 0.4802339971065521\n",
            "Epoch 95: train loss: 0.4757935106754303\n",
            "Epoch 96: train loss: 0.4714372158050537\n",
            "Epoch 97: train loss: 0.46716320514678955\n",
            "Epoch 98: train loss: 0.46296921372413635\n",
            "Epoch 99: train loss: 0.45885351300239563\n",
            "Epoch 100: train loss: 0.45481380820274353\n",
            "Epoch 101: train loss: 0.45084860920906067\n",
            "Epoch 102: train loss: 0.44695568084716797\n",
            "Epoch 103: train loss: 0.44313380122184753\n",
            "Epoch 104: train loss: 0.43938055634498596\n",
            "Epoch 105: train loss: 0.43569469451904297\n",
            "Epoch 106: train loss: 0.4320746660232544\n",
            "Epoch 107: train loss: 0.4285183846950531\n",
            "Epoch 108: train loss: 0.4250248670578003\n",
            "Epoch 109: train loss: 0.42159250378608704\n",
            "Epoch 110: train loss: 0.4182194769382477\n",
            "Epoch 111: train loss: 0.41490456461906433\n",
            "Epoch 112: train loss: 0.4116464853286743\n",
            "Epoch 113: train loss: 0.4084440767765045\n",
            "Epoch 114: train loss: 0.4052954614162445\n",
            "Epoch 115: train loss: 0.40219974517822266\n",
            "Epoch 116: train loss: 0.39915576577186584\n",
            "Epoch 117: train loss: 0.396162211894989\n",
            "Epoch 118: train loss: 0.39321786165237427\n",
            "Epoch 119: train loss: 0.39032164216041565\n",
            "Epoch 120: train loss: 0.3874724507331848\n",
            "Epoch 121: train loss: 0.38466912508010864\n",
            "Epoch 122: train loss: 0.3819108307361603\n",
            "Epoch 123: train loss: 0.37919631600379944\n",
            "Epoch 124: train loss: 0.3765248954296112\n",
            "Epoch 125: train loss: 0.37389522790908813\n",
            "Epoch 126: train loss: 0.3713066875934601\n",
            "Epoch 127: train loss: 0.3687582015991211\n",
            "Epoch 128: train loss: 0.3662489056587219\n",
            "Epoch 129: train loss: 0.36377811431884766\n",
            "Epoch 130: train loss: 0.3613448143005371\n",
            "Epoch 131: train loss: 0.35894814133644104\n",
            "Epoch 132: train loss: 0.35658740997314453\n",
            "Epoch 133: train loss: 0.3542619049549103\n",
            "Epoch 134: train loss: 0.3519708216190338\n",
            "Epoch 135: train loss: 0.3497132658958435\n",
            "Epoch 136: train loss: 0.3474889099597931\n",
            "Epoch 137: train loss: 0.3452965319156647\n",
            "Epoch 138: train loss: 0.3431359827518463\n",
            "Epoch 139: train loss: 0.3410062789916992\n",
            "Epoch 140: train loss: 0.3389069139957428\n",
            "Epoch 141: train loss: 0.33683717250823975\n",
            "Epoch 142: train loss: 0.3347965180873871\n",
            "Epoch 143: train loss: 0.3327843248844147\n",
            "Epoch 144: train loss: 0.33080005645751953\n",
            "Epoch 145: train loss: 0.32884305715560913\n",
            "Epoch 146: train loss: 0.32691290974617004\n",
            "Epoch 147: train loss: 0.3250090479850769\n",
            "Epoch 148: train loss: 0.32313084602355957\n",
            "Epoch 149: train loss: 0.3212778866291046\n",
            "Epoch 150: train loss: 0.31944963335990906\n",
            "Epoch 151: train loss: 0.31764569878578186\n",
            "Epoch 152: train loss: 0.31586554646492004\n",
            "Epoch 153: train loss: 0.31410863995552063\n",
            "Epoch 154: train loss: 0.3123745918273926\n",
            "Epoch 155: train loss: 0.31066298484802246\n",
            "Epoch 156: train loss: 0.308973491191864\n",
            "Epoch 157: train loss: 0.3073055148124695\n",
            "Epoch 158: train loss: 0.3056586980819702\n",
            "Epoch 159: train loss: 0.3040326237678528\n",
            "Epoch 160: train loss: 0.30242711305618286\n",
            "Epoch 161: train loss: 0.3008415102958679\n",
            "Epoch 162: train loss: 0.2992754876613617\n",
            "Epoch 163: train loss: 0.297728955745697\n",
            "Epoch 164: train loss: 0.29620125889778137\n",
            "Epoch 165: train loss: 0.29469215869903564\n",
            "Epoch 166: train loss: 0.2932012975215912\n",
            "Epoch 167: train loss: 0.2917284667491913\n",
            "Epoch 168: train loss: 0.2902732491493225\n",
            "Epoch 169: train loss: 0.28883519768714905\n",
            "Epoch 170: train loss: 0.2874142825603485\n",
            "Epoch 171: train loss: 0.28600993752479553\n",
            "Epoch 172: train loss: 0.2846221327781677\n",
            "Epoch 173: train loss: 0.2832503914833069\n",
            "Epoch 174: train loss: 0.2818945050239563\n",
            "Epoch 175: train loss: 0.2805541455745697\n",
            "Epoch 176: train loss: 0.27922916412353516\n",
            "Epoch 177: train loss: 0.27791914343833923\n",
            "Epoch 178: train loss: 0.2766239643096924\n",
            "Epoch 179: train loss: 0.27534329891204834\n",
            "Epoch 180: train loss: 0.2740769386291504\n",
            "Epoch 181: train loss: 0.2728246748447418\n",
            "Epoch 182: train loss: 0.27158617973327637\n",
            "Epoch 183: train loss: 0.2703612744808197\n",
            "Epoch 184: train loss: 0.2691498100757599\n",
            "Epoch 185: train loss: 0.26795148849487305\n",
            "Epoch 186: train loss: 0.2667659819126129\n",
            "Epoch 187: train loss: 0.2655932903289795\n",
            "Epoch 188: train loss: 0.2644331753253937\n",
            "Epoch 189: train loss: 0.263285368680954\n",
            "Epoch 190: train loss: 0.26214948296546936\n",
            "Epoch 191: train loss: 0.2610257565975189\n",
            "Epoch 192: train loss: 0.2599136531352997\n",
            "Epoch 193: train loss: 0.25881320238113403\n",
            "Epoch 194: train loss: 0.2577241063117981\n",
            "Epoch 195: train loss: 0.25664618611335754\n",
            "Epoch 196: train loss: 0.25557929277420044\n",
            "Epoch 197: train loss: 0.25452321767807007\n",
            "Epoch 198: train loss: 0.25347790122032166\n",
            "Epoch 199: train loss: 0.2524431645870209\n",
            "Epoch 200: train loss: 0.25141867995262146\n",
            "Epoch 201: train loss: 0.25040438771247864\n",
            "Epoch 202: train loss: 0.24940024316310883\n",
            "Epoch 203: train loss: 0.24840591847896576\n",
            "Epoch 204: train loss: 0.24742138385772705\n",
            "Epoch 205: train loss: 0.24644646048545837\n",
            "Epoch 206: train loss: 0.24548102915287018\n",
            "Epoch 207: train loss: 0.24452494084835052\n",
            "Epoch 208: train loss: 0.2435780167579651\n",
            "Epoch 209: train loss: 0.2426401674747467\n",
            "Epoch 210: train loss: 0.24171122908592224\n",
            "Epoch 211: train loss: 0.24079109728336334\n",
            "Epoch 212: train loss: 0.23987966775894165\n",
            "Epoch 213: train loss: 0.23897671699523926\n",
            "Epoch 214: train loss: 0.23808224499225616\n",
            "Epoch 215: train loss: 0.23719607293605804\n",
            "Epoch 216: train loss: 0.23631812632083893\n",
            "Epoch 217: train loss: 0.2354481965303421\n",
            "Epoch 218: train loss: 0.2345862090587616\n",
            "Epoch 219: train loss: 0.2337321639060974\n",
            "Epoch 220: train loss: 0.23288580775260925\n",
            "Epoch 221: train loss: 0.23204700648784637\n",
            "Epoch 222: train loss: 0.23121586441993713\n",
            "Epoch 223: train loss: 0.23039208352565765\n",
            "Epoch 224: train loss: 0.22957567870616913\n",
            "Epoch 225: train loss: 0.22876642644405365\n",
            "Epoch 226: train loss: 0.2279643416404724\n",
            "Epoch 227: train loss: 0.22716926038265228\n",
            "Epoch 228: train loss: 0.22638121247291565\n",
            "Epoch 229: train loss: 0.22559991478919983\n",
            "Epoch 230: train loss: 0.22482538223266602\n",
            "Epoch 231: train loss: 0.22405754029750824\n",
            "Epoch 232: train loss: 0.22329631447792053\n",
            "Epoch 233: train loss: 0.22254149615764618\n",
            "Epoch 234: train loss: 0.22179310023784637\n",
            "Epoch 235: train loss: 0.22105109691619873\n",
            "Epoch 236: train loss: 0.22031523287296295\n",
            "Epoch 237: train loss: 0.21958564221858978\n",
            "Epoch 238: train loss: 0.21886207163333893\n",
            "Epoch 239: train loss: 0.2181445211172104\n",
            "Epoch 240: train loss: 0.2174328863620758\n",
            "Epoch 241: train loss: 0.2167271375656128\n",
            "Epoch 242: train loss: 0.2160271853208542\n",
            "Epoch 243: train loss: 0.21533282101154327\n",
            "Epoch 244: train loss: 0.21464420855045319\n",
            "Epoch 245: train loss: 0.21396110951900482\n",
            "Epoch 246: train loss: 0.213283509016037\n",
            "Epoch 247: train loss: 0.2126113325357437\n",
            "Epoch 248: train loss: 0.2119446098804474\n",
            "Epoch 249: train loss: 0.21128302812576294\n",
            "Epoch 250: train loss: 0.21062681078910828\n",
            "Epoch 251: train loss: 0.2099757194519043\n",
            "Epoch 252: train loss: 0.2093297243118286\n",
            "Epoch 253: train loss: 0.20868878066539764\n",
            "Epoch 254: train loss: 0.20805276930332184\n",
            "Epoch 255: train loss: 0.20742176473140717\n",
            "Epoch 256: train loss: 0.20679554343223572\n",
            "Epoch 257: train loss: 0.20617416501045227\n",
            "Epoch 258: train loss: 0.20555756986141205\n",
            "Epoch 259: train loss: 0.2049456089735031\n",
            "Epoch 260: train loss: 0.20433834195137024\n",
            "Epoch 261: train loss: 0.2037356197834015\n",
            "Epoch 262: train loss: 0.2031373828649521\n",
            "Epoch 263: train loss: 0.2025437355041504\n",
            "Epoch 264: train loss: 0.2019544541835785\n",
            "Epoch 265: train loss: 0.20136955380439758\n",
            "Epoch 266: train loss: 0.20078898966312408\n",
            "Epoch 267: train loss: 0.20021265745162964\n",
            "Epoch 268: train loss: 0.19964058697223663\n",
            "Epoch 269: train loss: 0.1990727186203003\n",
            "Epoch 270: train loss: 0.19850890338420868\n",
            "Epoch 271: train loss: 0.19794927537441254\n",
            "Epoch 272: train loss: 0.19739367067813873\n",
            "Epoch 273: train loss: 0.1968420445919037\n",
            "Epoch 274: train loss: 0.196294367313385\n",
            "Epoch 275: train loss: 0.19575057923793793\n",
            "Epoch 276: train loss: 0.19521066546440125\n",
            "Epoch 277: train loss: 0.194674551486969\n",
            "Epoch 278: train loss: 0.19414228200912476\n",
            "Epoch 279: train loss: 0.1936136782169342\n",
            "Epoch 280: train loss: 0.19308879971504211\n",
            "Epoch 281: train loss: 0.1925676017999649\n",
            "Epoch 282: train loss: 0.1920500248670578\n",
            "Epoch 283: train loss: 0.19153599441051483\n",
            "Epoch 284: train loss: 0.19102555513381958\n",
            "Epoch 285: train loss: 0.1905185431241989\n",
            "Epoch 286: train loss: 0.1900150626897812\n",
            "Epoch 287: train loss: 0.18951499462127686\n",
            "Epoch 288: train loss: 0.18901824951171875\n",
            "Epoch 289: train loss: 0.18852493166923523\n",
            "Epoch 290: train loss: 0.18803498148918152\n",
            "Epoch 291: train loss: 0.1875482201576233\n",
            "Epoch 292: train loss: 0.1870647668838501\n",
            "Epoch 293: train loss: 0.18658459186553955\n",
            "Epoch 294: train loss: 0.18610747158527374\n",
            "Epoch 295: train loss: 0.18563351035118103\n",
            "Epoch 296: train loss: 0.18516281247138977\n",
            "Epoch 297: train loss: 0.18469509482383728\n",
            "Epoch 298: train loss: 0.1842304915189743\n",
            "Epoch 299: train loss: 0.18376882374286652\n",
            "Epoch 300: train loss: 0.18331022560596466\n",
            "Epoch 301: train loss: 0.1828545480966568\n",
            "Epoch 302: train loss: 0.1824018508195877\n",
            "Epoch 303: train loss: 0.18195202946662903\n",
            "Epoch 304: train loss: 0.18150511384010315\n",
            "Epoch 305: train loss: 0.1810610294342041\n",
            "Epoch 306: train loss: 0.18061979115009308\n",
            "Epoch 307: train loss: 0.18018129467964172\n",
            "Epoch 308: train loss: 0.1797455996274948\n",
            "Epoch 309: train loss: 0.179312601685524\n",
            "Epoch 310: train loss: 0.17888236045837402\n",
            "Epoch 311: train loss: 0.17845483124256134\n",
            "Epoch 312: train loss: 0.17802990972995758\n",
            "Epoch 313: train loss: 0.17760762572288513\n",
            "Epoch 314: train loss: 0.177187979221344\n",
            "Epoch 315: train loss: 0.17677085101604462\n",
            "Epoch 316: train loss: 0.17635636031627655\n",
            "Epoch 317: train loss: 0.17594432830810547\n",
            "Epoch 318: train loss: 0.17553482949733734\n",
            "Epoch 319: train loss: 0.1751278191804886\n",
            "Epoch 320: train loss: 0.1747232973575592\n",
            "Epoch 321: train loss: 0.17432120442390442\n",
            "Epoch 322: train loss: 0.17392146587371826\n",
            "Epoch 323: train loss: 0.17352423071861267\n",
            "Epoch 324: train loss: 0.17312926054000854\n",
            "Epoch 325: train loss: 0.17273665964603424\n",
            "Epoch 326: train loss: 0.17234642803668976\n",
            "Epoch 327: train loss: 0.17195844650268555\n",
            "Epoch 328: train loss: 0.17157281935214996\n",
            "Epoch 329: train loss: 0.17118944227695465\n",
            "Epoch 330: train loss: 0.17080821096897125\n",
            "Epoch 331: train loss: 0.17042933404445648\n",
            "Epoch 332: train loss: 0.17005257308483124\n",
            "Epoch 333: train loss: 0.1696780025959015\n",
            "Epoch 334: train loss: 0.16930562257766724\n",
            "Epoch 335: train loss: 0.1689353734254837\n",
            "Epoch 336: train loss: 0.1685672402381897\n",
            "Epoch 337: train loss: 0.16820122301578522\n",
            "Epoch 338: train loss: 0.16783730685710907\n",
            "Epoch 339: train loss: 0.16747541725635529\n",
            "Epoch 340: train loss: 0.16711561381816864\n",
            "Epoch 341: train loss: 0.16675777733325958\n",
            "Epoch 342: train loss: 0.16640201210975647\n",
            "Epoch 343: train loss: 0.16604822874069214\n",
            "Epoch 344: train loss: 0.16569636762142181\n",
            "Epoch 345: train loss: 0.16534656286239624\n",
            "Epoch 346: train loss: 0.1649986356496811\n",
            "Epoch 347: train loss: 0.16465266048908234\n",
            "Epoch 348: train loss: 0.1643085777759552\n",
            "Epoch 349: train loss: 0.1639663577079773\n",
            "Epoch 350: train loss: 0.1636260747909546\n",
            "Epoch 351: train loss: 0.16328759491443634\n",
            "Epoch 352: train loss: 0.1629510074853897\n",
            "Epoch 353: train loss: 0.16261623799800873\n",
            "Epoch 354: train loss: 0.16228322684764862\n",
            "Epoch 355: train loss: 0.16195209324359894\n",
            "Epoch 356: train loss: 0.16162270307540894\n",
            "Epoch 357: train loss: 0.161295086145401\n",
            "Epoch 358: train loss: 0.16096922755241394\n",
            "Epoch 359: train loss: 0.16064511239528656\n",
            "Epoch 360: train loss: 0.16032268106937408\n",
            "Epoch 361: train loss: 0.1600019335746765\n",
            "Epoch 362: train loss: 0.1596830040216446\n",
            "Epoch 363: train loss: 0.15936563909053802\n",
            "Epoch 364: train loss: 0.15905001759529114\n",
            "Epoch 365: train loss: 0.15873600542545319\n",
            "Epoch 366: train loss: 0.15842361748218536\n",
            "Epoch 367: train loss: 0.15811292827129364\n",
            "Epoch 368: train loss: 0.1578037589788437\n",
            "Epoch 369: train loss: 0.15749622881412506\n",
            "Epoch 370: train loss: 0.1571902632713318\n",
            "Epoch 371: train loss: 0.15688593685626984\n",
            "Epoch 372: train loss: 0.15658307075500488\n",
            "Epoch 373: train loss: 0.15628184378147125\n",
            "Epoch 374: train loss: 0.1559821218252182\n",
            "Epoch 375: train loss: 0.15568391978740692\n",
            "Epoch 376: train loss: 0.15538720786571503\n",
            "Epoch 377: train loss: 0.1550920307636261\n",
            "Epoch 378: train loss: 0.15479831397533417\n",
            "Epoch 379: train loss: 0.15450608730316162\n",
            "Epoch 380: train loss: 0.15421532094478607\n",
            "Epoch 381: train loss: 0.15392601490020752\n",
            "Epoch 382: train loss: 0.15363812446594238\n",
            "Epoch 383: train loss: 0.15335163474082947\n",
            "Epoch 384: train loss: 0.15306665003299713\n",
            "Epoch 385: train loss: 0.15278302133083344\n",
            "Epoch 386: train loss: 0.15250080823898315\n",
            "Epoch 387: train loss: 0.1522199958562851\n",
            "Epoch 388: train loss: 0.15194055438041687\n",
            "Epoch 389: train loss: 0.1516624093055725\n",
            "Epoch 390: train loss: 0.15138567984104156\n",
            "Epoch 391: train loss: 0.15111027657985687\n",
            "Epoch 392: train loss: 0.15083622932434082\n",
            "Epoch 393: train loss: 0.15056344866752625\n",
            "Epoch 394: train loss: 0.1502920240163803\n",
            "Epoch 395: train loss: 0.15002192556858063\n",
            "Epoch 396: train loss: 0.14975307881832123\n",
            "Epoch 397: train loss: 0.1494854837656021\n",
            "Epoch 398: train loss: 0.14921922981739044\n",
            "Epoch 399: train loss: 0.14895421266555786\n",
            "Epoch 400: train loss: 0.14869043231010437\n",
            "Epoch 401: train loss: 0.14842788875102997\n",
            "Epoch 402: train loss: 0.14816662669181824\n",
            "Epoch 403: train loss: 0.14790655672550201\n",
            "Epoch 404: train loss: 0.14764772355556488\n",
            "Epoch 405: train loss: 0.14739012718200684\n",
            "Epoch 406: train loss: 0.14713366329669952\n",
            "Epoch 407: train loss: 0.1468784511089325\n",
            "Epoch 408: train loss: 0.1466244012117386\n",
            "Epoch 409: train loss: 0.14637146890163422\n",
            "Epoch 410: train loss: 0.14611977338790894\n",
            "Epoch 411: train loss: 0.14586924016475677\n",
            "Epoch 412: train loss: 0.14561979472637177\n",
            "Epoch 413: train loss: 0.14537155628204346\n",
            "Epoch 414: train loss: 0.1451243758201599\n",
            "Epoch 415: train loss: 0.1448783427476883\n",
            "Epoch 416: train loss: 0.1446334719657898\n",
            "Epoch 417: train loss: 0.14438962936401367\n",
            "Epoch 418: train loss: 0.14414694905281067\n",
            "Epoch 419: train loss: 0.1439053863286972\n",
            "Epoch 420: train loss: 0.14366483688354492\n",
            "Epoch 421: train loss: 0.1434253752231598\n",
            "Epoch 422: train loss: 0.143187016248703\n",
            "Epoch 423: train loss: 0.1429496705532074\n",
            "Epoch 424: train loss: 0.14271342754364014\n",
            "Epoch 425: train loss: 0.14247825741767883\n",
            "Epoch 426: train loss: 0.14224404096603394\n",
            "Epoch 427: train loss: 0.142010897397995\n",
            "Epoch 428: train loss: 0.14177875220775604\n",
            "Epoch 429: train loss: 0.14154765009880066\n",
            "Epoch 430: train loss: 0.14131759107112885\n",
            "Epoch 431: train loss: 0.14108847081661224\n",
            "Epoch 432: train loss: 0.14086037874221802\n",
            "Epoch 433: train loss: 0.14063329994678497\n",
            "Epoch 434: train loss: 0.14040715992450714\n",
            "Epoch 435: train loss: 0.1401820182800293\n",
            "Epoch 436: train loss: 0.13995786011219025\n",
            "Epoch 437: train loss: 0.13973458111286163\n",
            "Epoch 438: train loss: 0.13951236009597778\n",
            "Epoch 439: train loss: 0.13929106295108795\n",
            "Epoch 440: train loss: 0.13907067477703094\n",
            "Epoch 441: train loss: 0.13885124027729034\n",
            "Epoch 442: train loss: 0.13863277435302734\n",
            "Epoch 443: train loss: 0.1384151726961136\n",
            "Epoch 444: train loss: 0.13819855451583862\n",
            "Epoch 445: train loss: 0.1379828155040741\n",
            "Epoch 446: train loss: 0.13776795566082\n",
            "Epoch 447: train loss: 0.13755400478839874\n",
            "Epoch 448: train loss: 0.1373409777879715\n",
            "Epoch 449: train loss: 0.1371288150548935\n",
            "Epoch 450: train loss: 0.1369175761938095\n",
            "Epoch 451: train loss: 0.1367071270942688\n",
            "Epoch 452: train loss: 0.1364976018667221\n",
            "Epoch 453: train loss: 0.13628891110420227\n",
            "Epoch 454: train loss: 0.13608112931251526\n",
            "Epoch 455: train loss: 0.13587422668933868\n",
            "Epoch 456: train loss: 0.135668084025383\n",
            "Epoch 457: train loss: 0.13546280562877655\n",
            "Epoch 458: train loss: 0.13525842130184174\n",
            "Epoch 459: train loss: 0.135054811835289\n",
            "Epoch 460: train loss: 0.13485205173492432\n",
            "Epoch 461: train loss: 0.1346501260995865\n",
            "Epoch 462: train loss: 0.13444899022579193\n",
            "Epoch 463: train loss: 0.13424867391586304\n",
            "Epoch 464: train loss: 0.1340491622686386\n",
            "Epoch 465: train loss: 0.13385047018527985\n",
            "Epoch 466: train loss: 0.13365252315998077\n",
            "Epoch 467: train loss: 0.13345541059970856\n",
            "Epoch 468: train loss: 0.13325905799865723\n",
            "Epoch 469: train loss: 0.13306351006031036\n",
            "Epoch 470: train loss: 0.1328687220811844\n",
            "Epoch 471: train loss: 0.1326746791601181\n",
            "Epoch 472: train loss: 0.1324814409017563\n",
            "Epoch 473: train loss: 0.13228894770145416\n",
            "Epoch 474: train loss: 0.13209722936153412\n",
            "Epoch 475: train loss: 0.13190621137619019\n",
            "Epoch 476: train loss: 0.13171601295471191\n",
            "Epoch 477: train loss: 0.13152647018432617\n",
            "Epoch 478: train loss: 0.1313377469778061\n",
            "Epoch 479: train loss: 0.13114970922470093\n",
            "Epoch 480: train loss: 0.13096240162849426\n",
            "Epoch 481: train loss: 0.1307758390903473\n",
            "Epoch 482: train loss: 0.13058999180793762\n",
            "Epoch 483: train loss: 0.13040482997894287\n",
            "Epoch 484: train loss: 0.130220428109169\n",
            "Epoch 485: train loss: 0.13003669679164886\n",
            "Epoch 486: train loss: 0.12985366582870483\n",
            "Epoch 487: train loss: 0.12967133522033691\n",
            "Epoch 488: train loss: 0.1294897049665451\n",
            "Epoch 489: train loss: 0.12930874526500702\n",
            "Epoch 490: train loss: 0.12912850081920624\n",
            "Epoch 491: train loss: 0.12894894182682037\n",
            "Epoch 492: train loss: 0.12877002358436584\n",
            "Epoch 493: train loss: 0.12859180569648743\n",
            "Epoch 494: train loss: 0.12841422855854034\n",
            "Epoch 495: train loss: 0.12823732197284698\n",
            "Epoch 496: train loss: 0.12806111574172974\n",
            "Epoch 497: train loss: 0.12788552045822144\n",
            "Epoch 498: train loss: 0.12771061062812805\n",
            "Epoch 499: train loss: 0.1275363266468048\n",
            "Epoch 500: train loss: 0.1273626685142517\n",
            "Epoch 501: train loss: 0.12718969583511353\n",
            "Epoch 502: train loss: 0.1270172894001007\n",
            "Epoch 503: train loss: 0.12684562802314758\n",
            "Epoch 504: train loss: 0.12667453289031982\n",
            "Epoch 505: train loss: 0.1265040934085846\n",
            "Epoch 506: train loss: 0.12633420526981354\n",
            "Epoch 507: train loss: 0.1261649876832962\n",
            "Epoch 508: train loss: 0.1259964108467102\n",
            "Epoch 509: train loss: 0.12582844495773315\n",
            "Epoch 510: train loss: 0.12566106021404266\n",
            "Epoch 511: train loss: 0.12549425661563873\n",
            "Epoch 512: train loss: 0.12532806396484375\n",
            "Epoch 513: train loss: 0.1251624971628189\n",
            "Epoch 514: train loss: 0.12499751150608063\n",
            "Epoch 515: train loss: 0.1248331069946289\n",
            "Epoch 516: train loss: 0.12466932833194733\n",
            "Epoch 517: train loss: 0.12450607866048813\n",
            "Epoch 518: train loss: 0.12434341758489609\n",
            "Epoch 519: train loss: 0.12418137490749359\n",
            "Epoch 520: train loss: 0.12401990592479706\n",
            "Epoch 521: train loss: 0.1238589808344841\n",
            "Epoch 522: train loss: 0.12369862198829651\n",
            "Epoch 523: train loss: 0.12353885918855667\n",
            "Epoch 524: train loss: 0.123379647731781\n",
            "Epoch 525: train loss: 0.12322098761796951\n",
            "Epoch 526: train loss: 0.1230628713965416\n",
            "Epoch 527: train loss: 0.12290532141923904\n",
            "Epoch 528: train loss: 0.12274833023548126\n",
            "Epoch 529: train loss: 0.12259184569120407\n",
            "Epoch 530: train loss: 0.12243595719337463\n",
            "Epoch 531: train loss: 0.1222805306315422\n",
            "Epoch 532: train loss: 0.12212570011615753\n",
            "Epoch 533: train loss: 0.12197141349315643\n",
            "Epoch 534: train loss: 0.12181764841079712\n",
            "Epoch 535: train loss: 0.1216643750667572\n",
            "Epoch 536: train loss: 0.12151169031858444\n",
            "Epoch 537: train loss: 0.12135948240756989\n",
            "Epoch 538: train loss: 0.12120778113603592\n",
            "Epoch 539: train loss: 0.12105661630630493\n",
            "Epoch 540: train loss: 0.12090595811605453\n",
            "Epoch 541: train loss: 0.12075585126876831\n",
            "Epoch 542: train loss: 0.12060622125864029\n",
            "Epoch 543: train loss: 0.12045708298683167\n",
            "Epoch 544: train loss: 0.12030846625566483\n",
            "Epoch 545: train loss: 0.12016035616397858\n",
            "Epoch 546: train loss: 0.12001273781061172\n",
            "Epoch 547: train loss: 0.11986561864614487\n",
            "Epoch 548: train loss: 0.11971897631883621\n",
            "Epoch 549: train loss: 0.11957282572984695\n",
            "Epoch 550: train loss: 0.11942719668149948\n",
            "Epoch 551: train loss: 0.11928201466798782\n",
            "Epoch 552: train loss: 0.11913733184337616\n",
            "Epoch 553: train loss: 0.1189931109547615\n",
            "Epoch 554: train loss: 0.11884937435388565\n",
            "Epoch 555: train loss: 0.1187061294913292\n",
            "Epoch 556: train loss: 0.11856333166360855\n",
            "Epoch 557: train loss: 0.1184210479259491\n",
            "Epoch 558: train loss: 0.11827917397022247\n",
            "Epoch 559: train loss: 0.11813778430223465\n",
            "Epoch 560: train loss: 0.11799684166908264\n",
            "Epoch 561: train loss: 0.11785639822483063\n",
            "Epoch 562: train loss: 0.11771634221076965\n",
            "Epoch 563: train loss: 0.11757679283618927\n",
            "Epoch 564: train loss: 0.11743772774934769\n",
            "Epoch 565: train loss: 0.11729902029037476\n",
            "Epoch 566: train loss: 0.117160864174366\n",
            "Epoch 567: train loss: 0.11702308803796768\n",
            "Epoch 568: train loss: 0.11688577383756638\n",
            "Epoch 569: train loss: 0.11674889177083969\n",
            "Epoch 570: train loss: 0.11661247164011002\n",
            "Epoch 571: train loss: 0.11647643148899078\n",
            "Epoch 572: train loss: 0.11634094268083572\n",
            "Epoch 573: train loss: 0.11620578169822693\n",
            "Epoch 574: train loss: 0.11607108265161514\n",
            "Epoch 575: train loss: 0.11593678593635559\n",
            "Epoch 576: train loss: 0.11580292880535126\n",
            "Epoch 577: train loss: 0.11566948145627975\n",
            "Epoch 578: train loss: 0.11553649604320526\n",
            "Epoch 579: train loss: 0.11540389806032181\n",
            "Epoch 580: train loss: 0.11527173966169357\n",
            "Epoch 581: train loss: 0.11513998359441757\n",
            "Epoch 582: train loss: 0.11500862240791321\n",
            "Epoch 583: train loss: 0.11487769335508347\n",
            "Epoch 584: train loss: 0.11474718898534775\n",
            "Epoch 585: train loss: 0.11461707204580307\n",
            "Epoch 586: train loss: 0.11448732018470764\n",
            "Epoch 587: train loss: 0.11435803025960922\n",
            "Epoch 588: train loss: 0.11422911286354065\n",
            "Epoch 589: train loss: 0.11410059034824371\n",
            "Epoch 590: train loss: 0.1139724850654602\n",
            "Epoch 591: train loss: 0.11384475231170654\n",
            "Epoch 592: train loss: 0.11371741443872452\n",
            "Epoch 593: train loss: 0.11359050124883652\n",
            "Epoch 594: train loss: 0.11346395313739777\n",
            "Epoch 595: train loss: 0.11333776265382767\n",
            "Epoch 596: train loss: 0.11321199685335159\n",
            "Epoch 597: train loss: 0.11308658868074417\n",
            "Epoch 598: train loss: 0.11296159029006958\n",
            "Epoch 599: train loss: 0.11283695697784424\n",
            "Epoch 600: train loss: 0.11271266639232635\n",
            "Epoch 601: train loss: 0.11258883029222488\n",
            "Epoch 602: train loss: 0.11246529966592789\n",
            "Epoch 603: train loss: 0.11234218627214432\n",
            "Epoch 604: train loss: 0.1122194156050682\n",
            "Epoch 605: train loss: 0.11209702491760254\n",
            "Epoch 606: train loss: 0.11197496950626373\n",
            "Epoch 607: train loss: 0.11185330152511597\n",
            "Epoch 608: train loss: 0.11173200607299805\n",
            "Epoch 609: train loss: 0.11161104589700699\n",
            "Epoch 610: train loss: 0.11149050295352936\n",
            "Epoch 611: train loss: 0.11137024313211441\n",
            "Epoch 612: train loss: 0.1112503856420517\n",
            "Epoch 613: train loss: 0.11113084107637405\n",
            "Epoch 614: train loss: 0.11101172119379044\n",
            "Epoch 615: train loss: 0.1108928695321083\n",
            "Epoch 616: train loss: 0.1107744351029396\n",
            "Epoch 617: train loss: 0.11065632104873657\n",
            "Epoch 618: train loss: 0.1105385348200798\n",
            "Epoch 619: train loss: 0.11042111366987228\n",
            "Epoch 620: train loss: 0.11030402034521103\n",
            "Epoch 621: train loss: 0.11018731445074081\n",
            "Epoch 622: train loss: 0.11007092148065567\n",
            "Epoch 623: train loss: 0.109954833984375\n",
            "Epoch 624: train loss: 0.10983911901712418\n",
            "Epoch 625: train loss: 0.10972374677658081\n",
            "Epoch 626: train loss: 0.10960869491100311\n",
            "Epoch 627: train loss: 0.10949395596981049\n",
            "Epoch 628: train loss: 0.10937957465648651\n",
            "Epoch 629: train loss: 0.10926550626754761\n",
            "Epoch 630: train loss: 0.10915178805589676\n",
            "Epoch 631: train loss: 0.109038345515728\n",
            "Epoch 632: train loss: 0.10892526805400848\n",
            "Epoch 633: train loss: 0.10881251841783524\n",
            "Epoch 634: train loss: 0.10870007425546646\n",
            "Epoch 635: train loss: 0.10858795046806335\n",
            "Epoch 636: train loss: 0.10847613215446472\n",
            "Epoch 637: train loss: 0.10836466401815414\n",
            "Epoch 638: train loss: 0.10825348645448685\n",
            "Epoch 639: train loss: 0.10814262181520462\n",
            "Epoch 640: train loss: 0.10803209245204926\n",
            "Epoch 641: train loss: 0.10792183876037598\n",
            "Epoch 642: train loss: 0.10781192034482956\n",
            "Epoch 643: train loss: 0.10770228505134583\n",
            "Epoch 644: train loss: 0.10759298503398895\n",
            "Epoch 645: train loss: 0.10748398303985596\n",
            "Epoch 646: train loss: 0.10737530142068863\n",
            "Epoch 647: train loss: 0.10726690292358398\n",
            "Epoch 648: train loss: 0.10715881735086441\n",
            "Epoch 649: train loss: 0.10705103725194931\n",
            "Epoch 650: train loss: 0.1069435253739357\n",
            "Epoch 651: train loss: 0.10683632642030716\n",
            "Epoch 652: train loss: 0.1067294254899025\n",
            "Epoch 653: train loss: 0.10662283003330231\n",
            "Epoch 654: train loss: 0.1065165176987648\n",
            "Epoch 655: train loss: 0.10641050338745117\n",
            "Epoch 656: train loss: 0.10630474984645844\n",
            "Epoch 657: train loss: 0.10619931668043137\n",
            "Epoch 658: train loss: 0.10609420388936996\n",
            "Epoch 659: train loss: 0.10598932206630707\n",
            "Epoch 660: train loss: 0.10588473081588745\n",
            "Epoch 661: train loss: 0.10578044503927231\n",
            "Epoch 662: train loss: 0.10567644238471985\n",
            "Epoch 663: train loss: 0.10557272285223007\n",
            "Epoch 664: train loss: 0.1054692491889\n",
            "Epoch 665: train loss: 0.10536608844995499\n",
            "Epoch 666: train loss: 0.10526320338249207\n",
            "Epoch 667: train loss: 0.10516060143709183\n",
            "Epoch 668: train loss: 0.10505826771259308\n",
            "Epoch 669: train loss: 0.10495621711015701\n",
            "Epoch 670: train loss: 0.10485441982746124\n",
            "Epoch 671: train loss: 0.10475292056798935\n",
            "Epoch 672: train loss: 0.10465166717767715\n",
            "Epoch 673: train loss: 0.10455067455768585\n",
            "Epoch 674: train loss: 0.10444998741149902\n",
            "Epoch 675: train loss: 0.1043495312333107\n",
            "Epoch 676: train loss: 0.10424940288066864\n",
            "Epoch 677: train loss: 0.1041494756937027\n",
            "Epoch 678: train loss: 0.10404984652996063\n",
            "Epoch 679: train loss: 0.10395048558712006\n",
            "Epoch 680: train loss: 0.1038513258099556\n",
            "Epoch 681: train loss: 0.1037525087594986\n",
            "Epoch 682: train loss: 0.1036539077758789\n",
            "Epoch 683: train loss: 0.1035555973649025\n",
            "Epoch 684: train loss: 0.1034575030207634\n",
            "Epoch 685: train loss: 0.10335966944694519\n",
            "Epoch 686: train loss: 0.10326211154460907\n",
            "Epoch 687: train loss: 0.10316479951143265\n",
            "Epoch 688: train loss: 0.10306776314973831\n",
            "Epoch 689: train loss: 0.10297095775604248\n",
            "Epoch 690: train loss: 0.10287444293498993\n",
            "Epoch 691: train loss: 0.10277809947729111\n",
            "Epoch 692: train loss: 0.10268206149339676\n",
            "Epoch 693: train loss: 0.10258625447750092\n",
            "Epoch 694: train loss: 0.10249070078134537\n",
            "Epoch 695: train loss: 0.10239537805318832\n",
            "Epoch 696: train loss: 0.10230034589767456\n",
            "Epoch 697: train loss: 0.10220551490783691\n",
            "Epoch 698: train loss: 0.10211092233657837\n",
            "Epoch 699: train loss: 0.10201658308506012\n",
            "Epoch 700: train loss: 0.10192249715328217\n",
            "Epoch 701: train loss: 0.1018286645412445\n",
            "Epoch 702: train loss: 0.10173503309488297\n",
            "Epoch 703: train loss: 0.10164164751768112\n",
            "Epoch 704: train loss: 0.10154850035905838\n",
            "Epoch 705: train loss: 0.10145560652017593\n",
            "Epoch 706: train loss: 0.10136295109987259\n",
            "Epoch 707: train loss: 0.10127050429582596\n",
            "Epoch 708: train loss: 0.10117831081151962\n",
            "Epoch 709: train loss: 0.1010863333940506\n",
            "Epoch 710: train loss: 0.10099463164806366\n",
            "Epoch 711: train loss: 0.10090310126543045\n",
            "Epoch 712: train loss: 0.10081184655427933\n",
            "Epoch 713: train loss: 0.10072076320648193\n",
            "Epoch 714: train loss: 0.10062992572784424\n",
            "Epoch 715: train loss: 0.10053931176662445\n",
            "Epoch 716: train loss: 0.10044898092746735\n",
            "Epoch 717: train loss: 0.10035882145166397\n",
            "Epoch 718: train loss: 0.10026892274618149\n",
            "Epoch 719: train loss: 0.10017921030521393\n",
            "Epoch 720: train loss: 0.10008972138166428\n",
            "Epoch 721: train loss: 0.10000045597553253\n",
            "Epoch 722: train loss: 0.09991145133972168\n",
            "Epoch 723: train loss: 0.09982264041900635\n",
            "Epoch 724: train loss: 0.09973403811454773\n",
            "Epoch 725: train loss: 0.09964567422866821\n",
            "Epoch 726: train loss: 0.09955750405788422\n",
            "Epoch 727: train loss: 0.09946955740451813\n",
            "Epoch 728: train loss: 0.09938184171915054\n",
            "Epoch 729: train loss: 0.09929431974887848\n",
            "Epoch 730: train loss: 0.09920702874660492\n",
            "Epoch 731: train loss: 0.09911993145942688\n",
            "Epoch 732: train loss: 0.09903309494256973\n",
            "Epoch 733: train loss: 0.09894641488790512\n",
            "Epoch 734: train loss: 0.09885995835065842\n",
            "Epoch 735: train loss: 0.09877372533082962\n",
            "Epoch 736: train loss: 0.09868766367435455\n",
            "Epoch 737: train loss: 0.09860184043645859\n",
            "Epoch 738: train loss: 0.09851622581481934\n",
            "Epoch 739: train loss: 0.09843079745769501\n",
            "Epoch 740: train loss: 0.09834560751914978\n",
            "Epoch 741: train loss: 0.09826057404279709\n",
            "Epoch 742: train loss: 0.09817580133676529\n",
            "Epoch 743: train loss: 0.09809121489524841\n",
            "Epoch 744: train loss: 0.09800679981708527\n",
            "Epoch 745: train loss: 0.09792260080575943\n",
            "Epoch 746: train loss: 0.0978386253118515\n",
            "Epoch 747: train loss: 0.0977548360824585\n",
            "Epoch 748: train loss: 0.09767121821641922\n",
            "Epoch 749: train loss: 0.09758783876895905\n",
            "Epoch 750: train loss: 0.0975046381354332\n",
            "Epoch 751: train loss: 0.09742163121700287\n",
            "Epoch 752: train loss: 0.09733883291482925\n",
            "Epoch 753: train loss: 0.09725619852542877\n",
            "Epoch 754: train loss: 0.0971737951040268\n",
            "Epoch 755: train loss: 0.09709157049655914\n",
            "Epoch 756: train loss: 0.0970095619559288\n",
            "Epoch 757: train loss: 0.0969277173280716\n",
            "Epoch 758: train loss: 0.0968460813164711\n",
            "Epoch 759: train loss: 0.09676463156938553\n",
            "Epoch 760: train loss: 0.09668334573507309\n",
            "Epoch 761: train loss: 0.09660227596759796\n",
            "Epoch 762: train loss: 0.09652137756347656\n",
            "Epoch 763: train loss: 0.09644069522619247\n",
            "Epoch 764: train loss: 0.09636019170284271\n",
            "Epoch 765: train loss: 0.09627985954284668\n",
            "Epoch 766: train loss: 0.09619973599910736\n",
            "Epoch 767: train loss: 0.09611979871988297\n",
            "Epoch 768: train loss: 0.0960400253534317\n",
            "Epoch 769: train loss: 0.09596045315265656\n",
            "Epoch 770: train loss: 0.09588103741407394\n",
            "Epoch 771: train loss: 0.09580180048942566\n",
            "Epoch 772: train loss: 0.09572276473045349\n",
            "Epoch 773: train loss: 0.09564392268657684\n",
            "Epoch 774: train loss: 0.09556524455547333\n",
            "Epoch 775: train loss: 0.09548678249120712\n",
            "Epoch 776: train loss: 0.09540844708681107\n",
            "Epoch 777: train loss: 0.09533027559518814\n",
            "Epoch 778: train loss: 0.09525234997272491\n",
            "Epoch 779: train loss: 0.09517455101013184\n",
            "Epoch 780: train loss: 0.09509693086147308\n",
            "Epoch 781: train loss: 0.09501952677965164\n",
            "Epoch 782: train loss: 0.09494227916002274\n",
            "Epoch 783: train loss: 0.09486520290374756\n",
            "Epoch 784: train loss: 0.09478827565908432\n",
            "Epoch 785: train loss: 0.09471150487661362\n",
            "Epoch 786: train loss: 0.09463495016098022\n",
            "Epoch 787: train loss: 0.09455857425928116\n",
            "Epoch 788: train loss: 0.09448234736919403\n",
            "Epoch 789: train loss: 0.09440632164478302\n",
            "Epoch 790: train loss: 0.09433041512966156\n",
            "Epoch 791: train loss: 0.0942547619342804\n",
            "Epoch 792: train loss: 0.09417920559644699\n",
            "Epoch 793: train loss: 0.09410383552312851\n",
            "Epoch 794: train loss: 0.09402862191200256\n",
            "Epoch 795: train loss: 0.09395360201597214\n",
            "Epoch 796: train loss: 0.09387870877981186\n",
            "Epoch 797: train loss: 0.09380403161048889\n",
            "Epoch 798: train loss: 0.09372948855161667\n",
            "Epoch 799: train loss: 0.09365509450435638\n",
            "Epoch 800: train loss: 0.0935809388756752\n",
            "Epoch 801: train loss: 0.09350687265396118\n",
            "Epoch 802: train loss: 0.09343298524618149\n",
            "Epoch 803: train loss: 0.09335926920175552\n",
            "Epoch 804: train loss: 0.09328571707010269\n",
            "Epoch 805: train loss: 0.0932123064994812\n",
            "Epoch 806: train loss: 0.09313908219337463\n",
            "Epoch 807: train loss: 0.09306599944829941\n",
            "Epoch 808: train loss: 0.09299305826425552\n",
            "Epoch 809: train loss: 0.09292033314704895\n",
            "Epoch 810: train loss: 0.09284771233797073\n",
            "Epoch 811: train loss: 0.09277528524398804\n",
            "Epoch 812: train loss: 0.09270298480987549\n",
            "Epoch 813: train loss: 0.09263087809085846\n",
            "Epoch 814: train loss: 0.09255890548229218\n",
            "Epoch 815: train loss: 0.09248709678649902\n",
            "Epoch 816: train loss: 0.09241542965173721\n",
            "Epoch 817: train loss: 0.09234392642974854\n",
            "Epoch 818: train loss: 0.09227257966995239\n",
            "Epoch 819: train loss: 0.092201367020607\n",
            "Epoch 820: train loss: 0.09213031828403473\n",
            "Epoch 821: train loss: 0.0920594111084938\n",
            "Epoch 822: train loss: 0.0919886976480484\n",
            "Epoch 823: train loss: 0.09191810339689255\n",
            "Epoch 824: train loss: 0.09184765815734863\n",
            "Epoch 825: train loss: 0.09177741408348083\n",
            "Epoch 826: train loss: 0.09170722961425781\n",
            "Epoch 827: train loss: 0.09163728356361389\n",
            "Epoch 828: train loss: 0.09156741201877594\n",
            "Epoch 829: train loss: 0.09149771928787231\n",
            "Epoch 830: train loss: 0.09142820537090302\n",
            "Epoch 831: train loss: 0.09135878086090088\n",
            "Epoch 832: train loss: 0.09128957241773605\n",
            "Epoch 833: train loss: 0.0912204384803772\n",
            "Epoch 834: train loss: 0.09115150570869446\n",
            "Epoch 835: train loss: 0.09108266234397888\n",
            "Epoch 836: train loss: 0.09101400524377823\n",
            "Epoch 837: train loss: 0.09094545990228653\n",
            "Epoch 838: train loss: 0.09087709337472916\n",
            "Epoch 839: train loss: 0.09080885350704193\n",
            "Epoch 840: train loss: 0.09074076265096664\n",
            "Epoch 841: train loss: 0.0906728208065033\n",
            "Epoch 842: train loss: 0.0906050056219101\n",
            "Epoch 843: train loss: 0.09053733199834824\n",
            "Epoch 844: train loss: 0.09046977013349533\n",
            "Epoch 845: train loss: 0.09040240198373795\n",
            "Epoch 846: train loss: 0.09033514559268951\n",
            "Epoch 847: train loss: 0.09026803821325302\n",
            "Epoch 848: train loss: 0.09020106494426727\n",
            "Epoch 849: train loss: 0.09013422578573227\n",
            "Epoch 850: train loss: 0.09006752818822861\n",
            "Epoch 851: train loss: 0.09000097215175629\n",
            "Epoch 852: train loss: 0.0899345800280571\n",
            "Epoch 853: train loss: 0.08986830711364746\n",
            "Epoch 854: train loss: 0.08980213850736618\n",
            "Epoch 855: train loss: 0.08973615616559982\n",
            "Epoch 856: train loss: 0.08967026323080063\n",
            "Epoch 857: train loss: 0.08960453420877457\n",
            "Epoch 858: train loss: 0.08953892439603806\n",
            "Epoch 859: train loss: 0.0894734337925911\n",
            "Epoch 860: train loss: 0.08940810710191727\n",
            "Epoch 861: train loss: 0.08934289962053299\n",
            "Epoch 862: train loss: 0.08927782624959946\n",
            "Epoch 863: train loss: 0.08921290934085846\n",
            "Epoch 864: train loss: 0.08914807438850403\n",
            "Epoch 865: train loss: 0.08908341079950333\n",
            "Epoch 866: train loss: 0.08901887387037277\n",
            "Epoch 867: train loss: 0.08895444869995117\n",
            "Epoch 868: train loss: 0.08889016509056091\n",
            "Epoch 869: train loss: 0.0888260155916214\n",
            "Epoch 870: train loss: 0.08876198530197144\n",
            "Epoch 871: train loss: 0.08869808167219162\n",
            "Epoch 872: train loss: 0.08863433450460434\n",
            "Epoch 873: train loss: 0.08857067674398422\n",
            "Epoch 874: train loss: 0.08850716054439545\n",
            "Epoch 875: train loss: 0.08844378590583801\n",
            "Epoch 876: train loss: 0.08838053047657013\n",
            "Epoch 877: train loss: 0.08831737190485\n",
            "Epoch 878: train loss: 0.08825438469648361\n",
            "Epoch 879: train loss: 0.08819147944450378\n",
            "Epoch 880: train loss: 0.0881287008523941\n",
            "Epoch 881: train loss: 0.08806606382131577\n",
            "Epoch 882: train loss: 0.08800358325242996\n",
            "Epoch 883: train loss: 0.08794117718935013\n",
            "Epoch 884: train loss: 0.08787892758846283\n",
            "Epoch 885: train loss: 0.08781678974628448\n",
            "Epoch 886: train loss: 0.08775478601455688\n",
            "Epoch 887: train loss: 0.08769285678863525\n",
            "Epoch 888: train loss: 0.08763109147548676\n",
            "Epoch 889: train loss: 0.0875694528222084\n",
            "Epoch 890: train loss: 0.08750790357589722\n",
            "Epoch 891: train loss: 0.08744651824235916\n",
            "Epoch 892: train loss: 0.08738522976636887\n",
            "Epoch 893: train loss: 0.08732402324676514\n",
            "Epoch 894: train loss: 0.08726297318935394\n",
            "Epoch 895: train loss: 0.0872020497918129\n",
            "Epoch 896: train loss: 0.0871412456035614\n",
            "Epoch 897: train loss: 0.08708055317401886\n",
            "Epoch 898: train loss: 0.08701996505260468\n",
            "Epoch 899: train loss: 0.08695951104164124\n",
            "Epoch 900: train loss: 0.08689916133880615\n",
            "Epoch 901: train loss: 0.08683893084526062\n",
            "Epoch 902: train loss: 0.08677881956100464\n",
            "Epoch 903: train loss: 0.0867188349366188\n",
            "Epoch 904: train loss: 0.08665898442268372\n",
            "Epoch 905: train loss: 0.08659921586513519\n",
            "Epoch 906: train loss: 0.08653956651687622\n",
            "Epoch 907: train loss: 0.0864800214767456\n",
            "Epoch 908: train loss: 0.08642061799764633\n",
            "Epoch 909: train loss: 0.08636131882667542\n",
            "Epoch 910: train loss: 0.08630212396383286\n",
            "Epoch 911: train loss: 0.08624307066202164\n",
            "Epoch 912: train loss: 0.08618409186601639\n",
            "Epoch 913: train loss: 0.08612524718046188\n",
            "Epoch 914: train loss: 0.08606649935245514\n",
            "Epoch 915: train loss: 0.08600789308547974\n",
            "Epoch 916: train loss: 0.0859493613243103\n",
            "Epoch 917: train loss: 0.08589095622301102\n",
            "Epoch 918: train loss: 0.08583266288042068\n",
            "Epoch 919: train loss: 0.08577446639537811\n",
            "Epoch 920: train loss: 0.08571640402078629\n",
            "Epoch 921: train loss: 0.08565846085548401\n",
            "Epoch 922: train loss: 0.0856005996465683\n",
            "Epoch 923: train loss: 0.08554283529520035\n",
            "Epoch 924: train loss: 0.08548519760370255\n",
            "Epoch 925: train loss: 0.08542768657207489\n",
            "Epoch 926: train loss: 0.0853702500462532\n",
            "Epoch 927: train loss: 0.08531296253204346\n",
            "Epoch 928: train loss: 0.08525575697422028\n",
            "Epoch 929: train loss: 0.08519865572452545\n",
            "Epoch 930: train loss: 0.08514165878295898\n",
            "Epoch 931: train loss: 0.08508478850126266\n",
            "Epoch 932: train loss: 0.0850280225276947\n",
            "Epoch 933: train loss: 0.08497133105993271\n",
            "Epoch 934: train loss: 0.08491475880146027\n",
            "Epoch 935: train loss: 0.08485832065343857\n",
            "Epoch 936: train loss: 0.08480194956064224\n",
            "Epoch 937: train loss: 0.08474570512771606\n",
            "Epoch 938: train loss: 0.08468955755233765\n",
            "Epoch 939: train loss: 0.08463351428508759\n",
            "Epoch 940: train loss: 0.08457758277654648\n",
            "Epoch 941: train loss: 0.08452172577381134\n",
            "Epoch 942: train loss: 0.08446601033210754\n",
            "Epoch 943: train loss: 0.08441036939620972\n",
            "Epoch 944: train loss: 0.08435485512018204\n",
            "Epoch 945: train loss: 0.08429941534996033\n",
            "Epoch 946: train loss: 0.08424410969018936\n",
            "Epoch 947: train loss: 0.08418885618448257\n",
            "Epoch 948: train loss: 0.08413375914096832\n",
            "Epoch 949: train loss: 0.08407873660326004\n",
            "Epoch 950: train loss: 0.08402381092309952\n",
            "Epoch 951: train loss: 0.08396900445222855\n",
            "Epoch 952: train loss: 0.08391427993774414\n",
            "Epoch 953: train loss: 0.08385966718196869\n",
            "Epoch 954: train loss: 0.083805151283741\n",
            "Epoch 955: train loss: 0.08375072479248047\n",
            "Epoch 956: train loss: 0.0836964100599289\n",
            "Epoch 957: train loss: 0.08364216238260269\n",
            "Epoch 958: train loss: 0.08358805626630783\n",
            "Epoch 959: train loss: 0.08353401720523834\n",
            "Epoch 960: train loss: 0.0834800973534584\n",
            "Epoch 961: train loss: 0.08342625945806503\n",
            "Epoch 962: train loss: 0.08337250351905823\n",
            "Epoch 963: train loss: 0.08331888914108276\n",
            "Epoch 964: train loss: 0.08326535671949387\n",
            "Epoch 965: train loss: 0.08321189135313034\n",
            "Epoch 966: train loss: 0.08315854519605637\n",
            "Epoch 967: train loss: 0.08310530334711075\n",
            "Epoch 968: train loss: 0.0830521434545517\n",
            "Epoch 969: train loss: 0.08299905806779861\n",
            "Epoch 970: train loss: 0.08294609189033508\n",
            "Epoch 971: train loss: 0.08289322257041931\n",
            "Epoch 972: train loss: 0.0828404352068901\n",
            "Epoch 973: train loss: 0.08278775215148926\n",
            "Epoch 974: train loss: 0.08273515850305557\n",
            "Epoch 975: train loss: 0.08268266916275024\n",
            "Epoch 976: train loss: 0.08263025432825089\n",
            "Epoch 977: train loss: 0.08257794380187988\n",
            "Epoch 978: train loss: 0.08252573758363724\n",
            "Epoch 979: train loss: 0.08247359097003937\n",
            "Epoch 980: train loss: 0.08242157101631165\n",
            "Epoch 981: train loss: 0.0823696181178093\n",
            "Epoch 982: train loss: 0.0823177769780159\n",
            "Epoch 983: train loss: 0.08226599544286728\n",
            "Epoch 984: train loss: 0.08221432566642761\n",
            "Epoch 985: train loss: 0.0821627601981163\n",
            "Epoch 986: train loss: 0.08211125433444977\n",
            "Epoch 987: train loss: 0.082059845328331\n",
            "Epoch 988: train loss: 0.08200856298208237\n",
            "Epoch 989: train loss: 0.08195734024047852\n",
            "Epoch 990: train loss: 0.08190622925758362\n",
            "Epoch 991: train loss: 0.0818551778793335\n",
            "Epoch 992: train loss: 0.08180421590805054\n",
            "Epoch 993: train loss: 0.08175333589315414\n",
            "Epoch 994: train loss: 0.0817025899887085\n",
            "Epoch 995: train loss: 0.08165188878774643\n",
            "Epoch 996: train loss: 0.08160131424665451\n",
            "Epoch 997: train loss: 0.08155079185962677\n",
            "Epoch 998: train loss: 0.08150036633014679\n",
            "Epoch 999: train loss: 0.08145003765821457\n"
          ]
        }
      ],
      "source": [
        "model.train() #set to train mode\n",
        "epoch = 1000    # 50\n",
        "for epoch in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    #make gradient update\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmslP6ujOLPT"
      },
      "source": [
        "### evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rolji8hUOLPT",
        "outputId": "37c2779a-1cd7-4f8b-c8c7-0266402eca30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train ACC:  tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "model.eval() #set model to eval mode\n",
        "\n",
        "#train \n",
        "y_pred = model(x_train) #predict\n",
        "y_pred = (y_pred>0.5).int().flatten() #argmax class lable\n",
        "train_acc = y_train.shape[0]/torch.sum(y_pred == y_train.int()) #check result: devide num of samples by num of correct ones, need to cast to int\n",
        "print(\"train ACC: \",train_acc.float())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test \n",
        "y_pred = model(x_test) #predict\n",
        "y_pred=(y_pred>0.5).int().flatten() #argmax class lable\n",
        "test_acc = y_test.shape[0]/torch.sum(y_pred == y_test.int()) #check result: devide num of samples by num of correct ones, need to cast to int\n",
        "print(\"test ACC: \",test_acc.float())"
      ],
      "metadata": {
        "id": "d0tDvOccUqj-",
        "outputId": "2cb1458b-7c71-43a9-99c0-133216961dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test ACC:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_test[:,0],x_test[:,1],c=y_pred)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "D5COihQBYArF",
        "outputId": "772376ef-f13c-4710-a656-4ea5201fa516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fd6104c51d0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B3Iyz0rmYPYH"
      },
      "execution_count": 57,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Lab_02_a_perceptron_in_PyTorch.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}